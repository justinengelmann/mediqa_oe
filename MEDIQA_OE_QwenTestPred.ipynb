{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b4d697c-7886-44fe-85cc-d274349faa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/g/ProjectsOverflow/MEDIQA/mediqa-oe/evaluation\n",
      "/mnt/g/ProjectsOverflow/MEDIQA\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (23347) < n_ctx_train (40960) -- the full capacity of the model will not be utilized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 1.7060s.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d61b97ee5754991abb4cdd507f9f93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx=0 took 13.0176s curr_sample[\"id\"]='primock57_1_5' len(pred)=2\n",
      "idx=1 took 2.6406s curr_sample[\"id\"]='acibench_D2N188_aci_clef_taskC_test3' len(pred)=2\n",
      "idx=2 took 7.6737s curr_sample[\"id\"]='primock57_2_1' len(pred)=1\n",
      "idx=3 took 2.5875s curr_sample[\"id\"]='acibench_D2N079_aci_valid' len(pred)=2\n",
      "idx=4 took 3.4930s curr_sample[\"id\"]='acibench_D2N069_virtassist_valid' len(pred)=3\n",
      "idx=5 took 2.3126s curr_sample[\"id\"]='acibench_D2N036_aci_train' len(pred)=2\n",
      "idx=6 took 2.9199s curr_sample[\"id\"]='acibench_D2N202_aci_clef_taskC_test3' len(pred)=3\n",
      "idx=7 took 1.8844s curr_sample[\"id\"]='acibench_D2N172_virtassist_clef_taskC_test3' len(pred)=1\n",
      "idx=8 took 2.8619s curr_sample[\"id\"]='acibench_D2N033_aci_train' len(pred)=4\n",
      "idx=9 took 2.3071s curr_sample[\"id\"]='acibench_D2N194_aci_clef_taskC_test3' len(pred)=2\n",
      "idx=10 took 2.4993s curr_sample[\"id\"]='acibench_D2N013_virtassist_train' len(pred)=2\n",
      "idx=11 took 3.3119s curr_sample[\"id\"]='acibench_D2N071_virtassist_valid' len(pred)=2\n",
      "idx=12 took 2.2211s curr_sample[\"id\"]='acibench_D2N048_aci_train' len(pred)=1\n",
      "idx=13 took 3.9918s curr_sample[\"id\"]='primock57_5_1' len(pred)=2\n",
      "idx=14 took 3.5363s curr_sample[\"id\"]='primock57_5_6' len(pred)=1\n",
      "idx=15 took 2.5349s curr_sample[\"id\"]='acibench_D2N159_aci_clinicalnlp_taskC_test2' len(pred)=2\n",
      "idx=16 took 6.0852s curr_sample[\"id\"]='acibench_D2N004_virtassist_train' len(pred)=5\n",
      "idx=17 took 1.9240s curr_sample[\"id\"]='acibench_D2N180_virtscribe_clef_taskC_test3' len(pred)=1\n",
      "idx=18 took 4.2318s curr_sample[\"id\"]='primock57_5_2' len(pred)=2\n",
      "idx=19 took 4.1218s curr_sample[\"id\"]='acibench_D2N143_virtscribe_clinicalnlp_taskC_test2' len(pred)=6\n",
      "idx=20 took 2.8109s curr_sample[\"id\"]='acibench_D2N147_aci_clinicalnlp_taskC_test2' len(pred)=3\n",
      "idx=21 was a dict, we made it a list\n",
      "idx=21 took 15.8702s curr_sample[\"id\"]='primock57_2_7' len(pred)=1\n",
      "idx=22 took 3.2895s curr_sample[\"id\"]='acibench_D2N127_aci_clinicalnlp_taskB_test1' len(pred)=2\n",
      "idx=23 took 4.1574s curr_sample[\"id\"]='acibench_D2N175_virtassist_clef_taskC_test3' len(pred)=4\n",
      "idx=24 took 2.6537s curr_sample[\"id\"]='acibench_D2N056_aci_train' len(pred)=3\n",
      "idx=25 was a dict, we made it a list\n",
      "idx=25 took 9.9665s curr_sample[\"id\"]='primock57_3_9' len(pred)=1\n",
      "idx=26 took 2.4954s curr_sample[\"id\"]='acibench_D2N154_aci_clinicalnlp_taskC_test2' len(pred)=2\n",
      "idx=27 took 4.1809s curr_sample[\"id\"]='acibench_D2N201_aci_clef_taskC_test3' len(pred)=2\n",
      "idx=28 took 2.4133s curr_sample[\"id\"]='acibench_D2N084_aci_valid' len(pred)=2\n",
      "idx=29 took 1.9398s curr_sample[\"id\"]='acibench_D2N179_virtscribe_clef_taskC_test3' len(pred)=1\n",
      "idx=30 took 7.8461s curr_sample[\"id\"]='acibench_D2N138_virtscribe_clinicalnlp_taskC_test2' len(pred)=5\n",
      "idx=31 took 2.6631s curr_sample[\"id\"]='acibench_D2N045_aci_train' len(pred)=3\n",
      "idx=32 took 4.7372s curr_sample[\"id\"]='acibench_D2N195_aci_clef_taskC_test3' len(pred)=5\n",
      "idx=33 was fixed with adding square brackets\n",
      "idx=33 took 2.6648s curr_sample[\"id\"]='primock57_2_3' len(pred)=0\n",
      "idx=34 took 2.7323s curr_sample[\"id\"]='acibench_D2N078_aci_valid' len(pred)=2\n",
      "idx=35 took 2.3323s curr_sample[\"id\"]='acibench_D2N137_virtassist_clinicalnlp_taskC_test2' len(pred)=1\n",
      "idx=36 took 4.0451s curr_sample[\"id\"]='primock57_1_9' len(pred)=1\n",
      "idx=37 took 7.1843s curr_sample[\"id\"]='primock57_1_11' len(pred)=2\n",
      "idx=38 took 5.3077s curr_sample[\"id\"]='primock57_5_3' len(pred)=2\n",
      "idx=39 took 2.4012s curr_sample[\"id\"]='acibench_D2N116_aci_clinicalnlp_taskB_test1' len(pred)=2\n",
      "idx=40 took 2.7777s curr_sample[\"id\"]='acibench_D2N184_virtscribe_clef_taskC_test3' len(pred)=2\n",
      "idx=41 took 5.0816s curr_sample[\"id\"]='acibench_D2N117_aci_clinicalnlp_taskB_test1' len(pred)=7\n",
      "idx=42 took 5.3706s curr_sample[\"id\"]='acibench_D2N087_aci_valid' len(pred)=6\n",
      "idx=43 took 6.1856s curr_sample[\"id\"]='acibench_D2N058_aci_train' len(pred)=9\n",
      "idx=44 took 4.0111s curr_sample[\"id\"]='acibench_D2N003_virtassist_train' len(pred)=3\n",
      "idx=45 took 5.0595s curr_sample[\"id\"]='acibench_D2N163_aci_clinicalnlp_taskC_test2' len(pred)=8\n",
      "idx=46 took 2.9368s curr_sample[\"id\"]='acibench_D2N100_virtscribe_clinicalnlp_taskB_test1' len(pred)=2\n",
      "idx=47 took 3.0072s curr_sample[\"id\"]='acibench_D2N106_aci_clinicalnlp_taskB_test1' len(pred)=3\n",
      "idx=48 took 3.2479s curr_sample[\"id\"]='acibench_D2N141_virtscribe_clinicalnlp_taskC_test2' len(pred)=1\n",
      "idx=49 took 4.4160s curr_sample[\"id\"]='acibench_D2N139_virtscribe_clinicalnlp_taskC_test2' len(pred)=2\n",
      "idx=50 took 3.9227s curr_sample[\"id\"]='acibench_D2N029_virtscribe_train' len(pred)=2\n",
      "idx=51 took 4.0156s curr_sample[\"id\"]='acibench_D2N052_aci_train' len(pred)=5\n",
      "idx=52 took 4.5490s curr_sample[\"id\"]='acibench_D2N192_aci_clef_taskC_test3' len(pred)=6\n",
      "idx=53 took 3.9442s curr_sample[\"id\"]='acibench_D2N171_virtassist_clef_taskC_test3' len(pred)=4\n",
      "idx=54 took 4.9938s curr_sample[\"id\"]='acibench_D2N134_virtassist_clinicalnlp_taskC_test2' len(pred)=4\n",
      "idx=55 took 1.9360s curr_sample[\"id\"]='acibench_D2N097_virtassist_clinicalnlp_taskB_test1' len(pred)=1\n",
      "idx=56 took 3.4320s curr_sample[\"id\"]='acibench_D2N123_aci_clinicalnlp_taskB_test1' len(pred)=5\n",
      "idx=57 was fixed with adding square brackets\n",
      "idx=57 took 6.7792s curr_sample[\"id\"]='primock57_1_7' len(pred)=2\n",
      "idx=58 took 4.4547s curr_sample[\"id\"]='acibench_D2N111_aci_clinicalnlp_taskB_test1' len(pred)=6\n",
      "idx=59 took 4.7533s curr_sample[\"id\"]='acibench_D2N032_virtscribe_train' len(pred)=3\n",
      "idx=60 took 2.1795s curr_sample[\"id\"]='acibench_D2N166_aci_clinicalnlp_taskC_test2' len(pred)=1\n",
      "idx=61 took 4.3798s curr_sample[\"id\"]='acibench_D2N035_aci_train' len(pred)=5\n",
      "idx=62 took 2.5768s curr_sample[\"id\"]='acibench_D2N062_aci_train' len(pred)=3\n",
      "idx=63 took 2.2112s curr_sample[\"id\"]='acibench_D2N129_virtassist_clinicalnlp_taskC_test2' len(pred)=1\n",
      "idx=64 took 3.3859s curr_sample[\"id\"]='acibench_D2N170_virtassist_clef_taskC_test3' len(pred)=2\n",
      "idx=65 took 6.4348s curr_sample[\"id\"]='primock57_2_2' len(pred)=3\n",
      "idx=66 took 3.6281s curr_sample[\"id\"]='acibench_D2N009_virtassist_train' len(pred)=3\n",
      "idx=67 was a dict, we made it a list\n",
      "idx=67 took 5.3104s curr_sample[\"id\"]='primock57_2_4' len(pred)=1\n",
      "idx=68 took 3.1791s curr_sample[\"id\"]='acibench_D2N186_aci_clef_taskC_test3' len(pred)=4\n",
      "idx=69 took 3.6864s curr_sample[\"id\"]='acibench_D2N050_aci_train' len(pred)=5\n",
      "idx=70 took 4.8731s curr_sample[\"id\"]='acibench_D2N198_aci_clef_taskC_test3' len(pred)=6\n",
      "idx=71 took 3.2215s curr_sample[\"id\"]='acibench_D2N161_aci_clinicalnlp_taskC_test2' len(pred)=3\n",
      "idx=72 took 2.2551s curr_sample[\"id\"]='acibench_D2N112_aci_clinicalnlp_taskB_test1' len(pred)=2\n",
      "idx=73 was a dict, we made it a list\n",
      "idx=73 took 3.4082s curr_sample[\"id\"]='primock57_5_7' len(pred)=1\n",
      "idx=74 took 2.9882s curr_sample[\"id\"]='acibench_D2N051_aci_train' len(pred)=3\n",
      "idx=75 took 4.4171s curr_sample[\"id\"]='acibench_D2N016_virtassist_train' len(pred)=3\n",
      "idx=76 took 6.1610s curr_sample[\"id\"]='acibench_D2N073_virtscribe_valid' len(pred)=4\n",
      "idx=77 was fixed with adding square brackets\n",
      "idx=77 took 4.0189s curr_sample[\"id\"]='primock57_4_8' len(pred)=0\n",
      "idx=78 took 4.0308s curr_sample[\"id\"]='acibench_D2N006_virtassist_train' len(pred)=2\n",
      "idx=79 took 3.7088s curr_sample[\"id\"]='acibench_D2N181_virtscribe_clef_taskC_test3' len(pred)=2\n",
      "idx=80 took 3.6654s curr_sample[\"id\"]='acibench_D2N114_aci_clinicalnlp_taskB_test1' len(pred)=3\n",
      "idx=81 took 4.8958s curr_sample[\"id\"]='primock57_3_4' len(pred)=3\n",
      "idx=82 took 6.2298s curr_sample[\"id\"]='acibench_D2N066_aci_train' len(pred)=9\n",
      "idx=83 took 2.9680s curr_sample[\"id\"]='acibench_D2N077_aci_valid' len(pred)=2\n",
      "idx=84 took 1.3400s curr_sample[\"id\"]='acibench_D2N187_aci_clef_taskC_test3' len(pred)=1\n",
      "idx=85 took 3.0671s curr_sample[\"id\"]='acibench_D2N046_aci_train' len(pred)=5\n",
      "idx=86 took 7.7287s curr_sample[\"id\"]='primock57_1_6' len(pred)=3\n",
      "idx=87 took 3.1729s curr_sample[\"id\"]='acibench_D2N019_virtassist_train' len(pred)=2\n",
      "idx=88 took 2.2302s curr_sample[\"id\"]='acibench_D2N176_virtassist_clef_taskC_test3' len(pred)=1\n",
      "idx=89 took 2.7043s curr_sample[\"id\"]='acibench_D2N064_aci_train' len(pred)=3\n",
      "idx=90 took 2.2226s curr_sample[\"id\"]='acibench_D2N083_aci_valid' len(pred)=2\n",
      "idx=91 took 6.3828s curr_sample[\"id\"]='acibench_D2N021_virtscribe_train' len(pred)=3\n",
      "idx=92 took 2.4822s curr_sample[\"id\"]='acibench_D2N153_aci_clinicalnlp_taskC_test2' len(pred)=2\n",
      "idx=93 took 2.1710s curr_sample[\"id\"]='acibench_D2N094_virtassist_clinicalnlp_taskB_test1' len(pred)=2\n",
      "idx=94 took 3.1290s curr_sample[\"id\"]='acibench_D2N193_aci_clef_taskC_test3' len(pred)=3\n",
      "idx=95 took 4.6607s curr_sample[\"id\"]='acibench_D2N001_virtassist_train' len(pred)=4\n",
      "idx=96 took 4.2989s curr_sample[\"id\"]='primock57_2_8' len(pred)=2\n",
      "idx=97 took 6.2359s curr_sample[\"id\"]='acibench_D2N144_virtscribe_clinicalnlp_taskC_test2' len(pred)=4\n",
      "idx=98 took 3.1079s curr_sample[\"id\"]='primock57_3_5' len(pred)=1\n",
      "idx=99 took 2.1170s curr_sample[\"id\"]='acibench_D2N132_virtassist_clinicalnlp_taskC_test2' len(pred)=1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from llama_cpp import Llama, LlamaGrammar\n",
    "from llama_cpp.llama_speculative import LlamaPromptLookupDecoding\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "%cd mediqa-oe/evaluation\n",
    "from evaluate_oe import evaluate_sample\n",
    "evaluate_sample\n",
    "%cd ../..\n",
    "\n",
    "with open('data/orders_data_transcript.json', 'r') as f:\n",
    "    traindata = json.loads(f.read())\n",
    "\n",
    "\n",
    "with open('data/test_orders_data_transcript.json', 'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "startmodelloading_time = time.time()\n",
    "\n",
    "try:\n",
    "    llm\n",
    "except NameError:\n",
    "    print('Loading model')\n",
    "    llm = Llama(\n",
    "        # model_path=\"/home/justin/llama/Qwen3-8B-Q5_K_M.gguf\",  \n",
    "        model_path=\"/home/justin/llama/Qwen3-14B-Q4_K_M.gguf\",  \n",
    "        # model_path=\"/home/justin/llama/Qwen3-14B-UD-Q4_K_XL.gguf\",  \n",
    "        # model_path=\"/home/justin/llama/Qwen3-4B-Q6_K.gguf\",  \n",
    "        draft_model=LlamaPromptLookupDecoding(),\n",
    "        logits_all=True,\n",
    "        n_gpu_layers=-1,\n",
    "        flash_attn=True,\n",
    "        n_ctx=int(4096*5.7),\n",
    "        verbose=False,\n",
    "        n_threads=os.cpu_count() - 2\n",
    "    )\n",
    "    print(f'Loaded model {time.time()-startmodelloading_time:.4f}s.')\n",
    "\n",
    "examplestr = \\\n",
    "f\"\"\"\n",
    "EXAMPLE1START\n",
    "Transcript:\n",
    "{traindata['train'][0]['transcript']}\n",
    "Desired output:\n",
    "{traindata['train'][0]['expected_orders']}\n",
    "EXAMPLE1END\n",
    "\n",
    "EXAMPLE2START\n",
    "Transcript:\n",
    "{traindata['train'][-1]['transcript']}\n",
    "Desired output:\n",
    "{traindata['train'][-1]['expected_orders']}\n",
    "EXAMPLE2END\n",
    "\"\"\".replace('\\'', '\"')\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are an assistant for extracting medical orders from transcripts of patient doctor conversations.\n",
    "\n",
    "Medical order extraction involves identifying and structuring various medical orders —such as medications, imaging studies, lab tests, and follow-ups— based on doctor-patient conversations. \n",
    "\n",
    "The conversation is given to you in the format of a list of dicts with turn_id, speaker (doctor or patient), and transcript for each turn.\n",
    "\n",
    "You are to return a list of dicts with these keys: order_type, description, reason, and provenance. \n",
    "\n",
    "1. Return a list with one dict for each order from the conversation. Your output will be parsed with json.loads().\n",
    "2. If there is only a single order, still return a list.\n",
    "3. There are only four allowed values for the order_type: \"medication\", \"lab\", \"followup\", \"imaging\"\n",
    "4. Provenance should be a list of ints relating to the turn ids where the order was made, including directly preceeding turns where the reason was mentioned.\n",
    "5. Quote the reason verbatim from the text.\n",
    "6. Only list *new* or repeat orders. Do not list things that the patient is to continue doing that are mentioned in passing. Do not list previous exams.\n",
    "7. The above point (6.) is very important. Orders that have a \"continue\" status (e.g. \"we will continue with xanax XXmg\") are NOT considered valid orders, since we dont need to place a specific order in EHR for instance.\n",
    "8. Lab orders are fine-grained, i.e. each test is one order.\n",
    "9. If the doctor suggests an over the counter medication (e.g. pain killers), we also count that as an order - UNLESS the patient is already taking it (remember rule 6!)\n",
    "\n",
    "Make sure your output is a list (i.e. starts and ends with square brackets) of dicts, separated by commas.\n",
    "\n",
    "Examples:\n",
    "{examplestr}\n",
    "\"\"\"\n",
    "\n",
    "data_to_use = data['test']\n",
    "all_preds = {}\n",
    "all_metrics = {}\n",
    "metrics_per_sample = {}\n",
    "for idx, curr_sample in enumerate(tqdm(data_to_use)):\n",
    "    curr_sample = data_to_use[idx]\n",
    "    curr_transcript = curr_sample['transcript']\n",
    "    \n",
    "    user_prompt = f\"Please process this transcript. Reply only with the valid response in the desired format.\\nTRANSCRIPT START{curr_transcript}\\nTRANSCRIPT END. Please follow all the rules and instructions carefully\"\n",
    "    prompt=f\"\"\"\n",
    "    <|im_start|>system{system_prompt}<|im_end|>\n",
    "    <|im_start|>user\\n{user_prompt} \\\\nothink<|im_end|>\n",
    "    <|im_start|>assistant\\n<think>\\n</think>\\n\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    response = llm.create_completion(\n",
    "        prompt=prompt,\n",
    "        max_tokens=int(4096*0.5),\n",
    "        temperature=0., top_k=1, top_p=1.0,\n",
    "        stop=[]\n",
    "    )\n",
    "    curr_time = time.time()-start\n",
    "    \n",
    "    pred = response['choices'][0]['text']\n",
    "    if \"</think>\" in pred:\n",
    "        thought_trace = pred.split('</think>')[0]\n",
    "        print(thought_trace)\n",
    "        pred = pred.split('</think>')[-1]\n",
    "    try:\n",
    "        try:\n",
    "            pred = json.loads(pred)\n",
    "        except:\n",
    "            pred = json.loads('['+pred+']')\n",
    "            print(f'{idx=} was fixed with adding square brackets')\n",
    "        if isinstance(pred, dict):\n",
    "            print(f'{idx=} was a dict, we made it a list')\n",
    "            pred = [pred]\n",
    "    except:\n",
    "        print(f'{idx} is not proper json.\\n{pred}')\n",
    "        pred = []\n",
    "\n",
    "    all_preds[curr_sample['id']] = pred\n",
    "    print(f'{idx=} took {curr_time:.4f}s {curr_sample[\"id\"]=} {len(pred)=}')\n",
    "    # print()\n",
    "\n",
    "print('Done')\n",
    "\n",
    "with open('data/test_qw14B_v5dot6_ex_specdec_v2c.json', 'w') as f:\n",
    "    json.dump(all_preds, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7925e6-cd95-45cc-aa5c-3657a2d75c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f44decb-71f3-4c4b-bd3a-554486475832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712e928-e871-414b-8065-fd2479493b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94947b-fde1-4d56-a977-a9b1543ed865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

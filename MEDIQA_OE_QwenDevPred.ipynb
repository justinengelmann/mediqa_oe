{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd80e83b-fc7d-4ef3-bbbd-5cd74e7665a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/g/ProjectsOverflow/MEDIQA/mediqa-oe/evaluation\n",
      "/mnt/g/ProjectsOverflow/MEDIQA\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (23347) < n_ctx_train (40960) -- the full capacity of the model will not be utilized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 3.4683s.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beec76ee7c304c9b9195ea5836752e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx=0 took 57.3408s curr_sample[\"id\"]='acibench_D2N182_virtscribe_clef_taskC_test3'\n",
      "Desc F1:0.190 (0.250/0.154)  Reas F1:0.267 (0.500/0.182)  OTyp F1:0.500 (0.500/0.500)  Prov F1:0.333 (0.333/0.333)\n",
      "\n",
      "idx=1 took 21.3361s curr_sample[\"id\"]='acibench_D2N174_virtassist_clef_taskC_test3'\n",
      "Desc F1:0.909 (0.833/1.000)  Reas F1:0.877 (0.833/0.926)  OTyp F1:1.000 (1.000/1.000)  Prov F1:0.638 (0.611/0.667)\n",
      "\n",
      "idx=2 took 18.9744s curr_sample[\"id\"]='primock57_5_12'\n",
      "Desc F1:0.077 (1.000/0.040)  Reas F1:0.167 (1.000/0.091)  OTyp F1:1.000 (1.000/1.000)  Prov F1:0.400 (0.500/0.333)\n",
      "\n",
      "idx=3 took 24.1653s curr_sample[\"id\"]='acibench_D2N140_virtscribe_clinicalnlp_taskC_test2'\n",
      "Desc F1:0.541 (0.870/0.393)  Reas F1:0.091 (0.500/0.050)  OTyp F1:0.667 (1.000/0.500)  Prov F1:0.462 (0.600/0.375)\n",
      "\n",
      "idx=4 took 18.4539s curr_sample[\"id\"]='acibench_D2N067_aci_train'\n",
      "Desc F1:0.800 (1.000/0.667)  Reas F1:0.000 (0.000/0.000)  OTyp F1:0.800 (1.000/0.667)  Prov F1:0.706 (0.750/0.667)\n",
      "\n",
      "idx=5 took 51.2579s curr_sample[\"id\"]='primock57_4_1'\n",
      "Desc F1:0.000 (0.000/0.000)  Reas F1:0.000 (0.000/0.000)  OTyp F1:0.000 (0.000/0.000)  Prov F1:0.000 (0.000/0.000)\n",
      "\n",
      "idx=6 took 25.7697s curr_sample[\"id\"]='acibench_D2N177_virtassist_clef_taskC_test3'\n",
      "Desc F1:0.654 (0.758/0.575)  Reas F1:0.571 (1.000/0.400)  OTyp F1:0.750 (1.000/0.600)  Prov F1:0.698 (0.833/0.600)\n",
      "\n",
      "idx=7 took 18.6857s curr_sample[\"id\"]='acibench_D2N136_virtassist_clinicalnlp_taskC_test2'\n",
      "Desc F1:0.857 (1.000/0.750)  Reas F1:0.693 (0.778/0.625)  OTyp F1:0.857 (1.000/0.750)  Prov F1:0.714 (0.833/0.625)\n",
      "\n",
      "idx=8 took 20.8838s curr_sample[\"id\"]='acibench_D2N089_virtassist_clinicalnlp_taskB_test1'\n",
      "Desc F1:0.500 (1.000/0.333)  Reas F1:0.500 (1.000/0.333)  OTyp F1:0.500 (1.000/0.333)  Prov F1:0.250 (0.500/0.167)\n",
      "\n",
      "idx=9 took 14.9998s curr_sample[\"id\"]='acibench_D2N109_aci_clinicalnlp_taskB_test1'\n",
      "Desc F1:0.780 (1.000/0.640)  Reas F1:0.651 (0.792/0.553)  OTyp F1:0.889 (1.000/0.800)  Prov F1:0.000 (0.000/0.000)\n",
      "\n",
      "idx=10 took 22.2416s curr_sample[\"id\"]='acibench_D2N002_virtassist_train'\n",
      "Desc F1:1.000 (1.000/1.000)  Reas F1:0.615 (0.571/0.667)  OTyp F1:1.000 (1.000/1.000)  Prov F1:0.714 (0.556/1.000)\n",
      "\n",
      "idx=11 took 24.1397s curr_sample[\"id\"]='acibench_D2N068_virtassist_valid'\n",
      "Desc F1:0.667 (1.000/0.500)  Reas F1:0.462 (1.000/0.300)  OTyp F1:0.667 (1.000/0.500)  Prov F1:0.400 (1.000/0.250)\n",
      "\n",
      "idx=12 took 16.3151s curr_sample[\"id\"]='acibench_D2N061_aci_train'\n",
      "Desc F1:0.515 (0.700/0.407)  Reas F1:0.143 (0.154/0.133)  OTyp F1:0.800 (1.000/0.667)  Prov F1:0.800 (1.000/0.667)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 106\u001b[39m\n\u001b[32m    100\u001b[39m prompt=\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[33m<|im_start|>system\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msystem_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m<|im_end|>\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[33m<|im_start|>user\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00muser_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mnothink<|im_end|>\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[33m<|im_start|>assistant\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m<think>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m</think>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    105\u001b[39m start = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m4096\u001b[39;49m\u001b[43m*\u001b[49m\u001b[32;43m0.33\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m curr_time = time.time()-start\n\u001b[32m    113\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurr_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurr_sample[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/llm/lib/python3.11/site-packages/llama_cpp/llama.py:1835\u001b[39m, in \u001b[36mLlama.create_completion\u001b[39m\u001b[34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[39m\n\u001b[32m   1833\u001b[39m     chunks: Iterator[CreateCompletionStreamResponse] = completion_or_chunks\n\u001b[32m   1834\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n\u001b[32m-> \u001b[39m\u001b[32m1835\u001b[39m completion: Completion = \u001b[38;5;28mnext\u001b[39m(completion_or_chunks)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   1836\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/llm/lib/python3.11/site-packages/llama_cpp/llama.py:1320\u001b[39m, in \u001b[36mLlama._create_completion\u001b[39m\u001b[34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[39m\n\u001b[32m   1318\u001b[39m finish_reason = \u001b[33m\"\u001b[39m\u001b[33mlength\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1319\u001b[39m multibyte_fix = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1320\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mllama_cpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mllama_token_is_eog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/llm/lib/python3.11/site-packages/llama_cpp/llama.py:912\u001b[39m, in \u001b[36mLlama.generate\u001b[39m\u001b[34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    913\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx < \u001b[38;5;28mself\u001b[39m.n_tokens:\n\u001b[32m    914\u001b[39m         token = \u001b[38;5;28mself\u001b[39m.sample(\n\u001b[32m    915\u001b[39m             top_k=top_k,\n\u001b[32m    916\u001b[39m             top_p=top_p,\n\u001b[32m   (...)\u001b[39m\u001b[32m    930\u001b[39m             idx=sample_idx,\n\u001b[32m    931\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/llm/lib/python3.11/site-packages/llama_cpp/llama.py:654\u001b[39m, in \u001b[36mLlama.eval\u001b[39m\u001b[34m(self, tokens)\u001b[39m\n\u001b[32m    651\u001b[39m     rows = n_tokens\n\u001b[32m    652\u001b[39m     cols = \u001b[38;5;28mself\u001b[39m._n_vocab\n\u001b[32m    653\u001b[39m     logits = np.ctypeslib.as_array(\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, shape=(rows * cols,)\n\u001b[32m    655\u001b[39m     )\n\u001b[32m    656\u001b[39m     \u001b[38;5;28mself\u001b[39m.scores[n_past : n_past + n_tokens, :].reshape(-\u001b[32m1\u001b[39m)[::] = logits\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;66;03m# rows = 1\u001b[39;00m\n\u001b[32m    659\u001b[39m     \u001b[38;5;66;03m# cols = self._n_vocab\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    663\u001b[39m     \u001b[38;5;66;03m# self.scores[n_past + n_tokens - 1, :].reshape(-1)[::] = logits\u001b[39;00m\n\u001b[32m    664\u001b[39m     \u001b[38;5;66;03m# NOTE: Now that sampling is done inside the sampler, logits are only needed for logprobs which requires logits_all\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/llm/lib/python3.11/site-packages/llama_cpp/_internals.py:317\u001b[39m, in \u001b[36mLlamaContext.get_logits\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_logits\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllama_cpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mllama_get_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from llama_cpp import Llama, LlamaGrammar\n",
    "from llama_cpp.llama_speculative import LlamaPromptLookupDecoding\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "%cd mediqa-oe/evaluation\n",
    "from evaluate_oe import evaluate_sample\n",
    "evaluate_sample\n",
    "%cd ../..\n",
    "\n",
    "with open('data/orders_data_transcript.json', 'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "allids = [_['id'] for _ in data['dev']]\n",
    "\n",
    "dev_extract = data['dev'][:12]\n",
    "\n",
    "dev_extract_orders = {\n",
    "    d['id']: d['expected_orders'] for d in dev_extract\n",
    "}\n",
    "with open('data/dev_extract_orders.json', 'w') as f:\n",
    "    json.dump(dev_extract_orders, f)\n",
    "\n",
    "startmodelloading_time = time.time()\n",
    "\n",
    "try:\n",
    "    llm\n",
    "except NameError:\n",
    "    print('Loading model')\n",
    "    llm = Llama(\n",
    "        # model_path=\"/home/justin/llama/Qwen3-8B-Q5_K_M.gguf\",  \n",
    "        # model_path=\"/home/justin/llama/Qwen3-14B-Q4_K_M.gguf\",  \n",
    "        # model_path=\"/home/justin/llama/Qwen3-14B-UD-Q4_K_XL.gguf\",  \n",
    "        model_path=\"/home/justin/llama/Qwen3-14B-UD-Q5_K_XL.gguf\",  \n",
    "        # model_path=\"/home/justin/llama/Qwen3-4B-Q6_K.gguf\",  \n",
    "        draft_model=LlamaPromptLookupDecoding(),\n",
    "        logits_all=True,\n",
    "        n_gpu_layers=-1,\n",
    "        flash_attn=True,\n",
    "        n_ctx=int(4096*5.7),\n",
    "        verbose=False,\n",
    "        n_threads=os.cpu_count() - 2\n",
    "    )\n",
    "    print(f'Loaded model {time.time()-startmodelloading_time:.4f}s.')\n",
    "\n",
    "examplestr = \\\n",
    "f\"\"\"\n",
    "EXAMPLE1START\n",
    "Transcript:\n",
    "{data['train'][0]['transcript']}\n",
    "Desired output:\n",
    "{data['train'][0]['expected_orders']}\n",
    "EXAMPLE1END\n",
    "\n",
    "EXAMPLE2START\n",
    "Transcript:\n",
    "{data['train'][-1]['transcript']}\n",
    "Desired output:\n",
    "{data['train'][-1]['expected_orders']}\n",
    "EXAMPLE2END\n",
    "\"\"\".replace('\\'', '\"')\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are an assistant for extracting medical orders from transcripts of patient doctor conversations.\n",
    "\n",
    "Medical order extraction involves identifying and structuring various medical orders —such as medications, imaging studies, lab tests, and follow-ups— based on doctor-patient conversations. \n",
    "\n",
    "The conversation is given to you in the format of a list of dicts with turn_id, speaker (doctor or patient), and transcript for each turn.\n",
    "\n",
    "You are to return a list of dicts with these keys: order_type, description, reason, and provenance. \n",
    "\n",
    "1. Return a list with one dict for each order from the conversation. Your output will be parsed with json.loads().\n",
    "2. If there is only a single order, still return a list.\n",
    "3. There are only four allowed values for the order_type: \"medication\", \"lab\", \"followup\", \"imaging\"\n",
    "4. Provenance should be a list of ints relating to the turn ids where the order was made, including directly preceeding turns where the reason was mentioned.\n",
    "5. Quote the reason verbatim from the text.\n",
    "6. Only list *new* or repeat orders. Do not list things that the patient is to continue doing that are mentioned in passing. Do not list previous exams.\n",
    "7. The above point (6.) is very important. Orders that have a \"continue\" status (e.g. \"we will continue with xanax XXmg\") are NOT considered valid orders, since we dont need to place a specific order in EHR for instance.\n",
    "8. Lab orders are fine-grained, i.e. each test is one order.\n",
    "9. If the doctor suggests an over the counter medication (e.g. pain killers), we also count that as an order - UNLESS the patient is already taking it (remember rule 6!)\n",
    "\n",
    "Make sure your output is a list (i.e. starts and ends with square brackets) of dicts, separated by commas.\n",
    "\n",
    "Examples:\n",
    "{examplestr}\n",
    "\"\"\"\n",
    "\n",
    "data_to_use = data['dev'][:]\n",
    "all_preds = {}\n",
    "all_metrics = {}\n",
    "metrics_per_sample = {}\n",
    "for idx, curr_sample in enumerate(tqdm(data_to_use)):\n",
    "    curr_sample = data_to_use[idx]\n",
    "    curr_transcript = curr_sample['transcript']\n",
    "    \n",
    "    user_prompt = f\"Please process this transcript. Reply only with the valid response in the desired format.\\nTRANSCRIPT START{curr_transcript}\\nTRANSCRIPT END. Please follow all the rules and instructions carefully\"\n",
    "    prompt=f\"\"\"\n",
    "    <|im_start|>system{system_prompt}<|im_end|>\n",
    "    <|im_start|>user\\n{user_prompt} \\\\nothink<|im_end|>\n",
    "    <|im_start|>assistant\\n<think>\\n</think>\\n\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    response = llm.create_completion(\n",
    "        prompt=prompt,\n",
    "        max_tokens=int(4096*0.33),\n",
    "        temperature=0., top_k=1, top_p=1.0,\n",
    "        stop=[]\n",
    "    )\n",
    "    curr_time = time.time()-start\n",
    "    print(f'{idx=} took {curr_time:.4f}s {curr_sample[\"id\"]=}')\n",
    "    \n",
    "    pred = response['choices'][0]['text']\n",
    "    if \"</think>\" in pred:\n",
    "        thought_trace = pred.split('</think>')[0]\n",
    "        print(thought_trace)\n",
    "        pred = pred.split('</think>')[-1]\n",
    "    try:\n",
    "        try:\n",
    "            pred = json.loads(pred)\n",
    "        except:\n",
    "            pred = json.loads('['+pred+']')\n",
    "            print(f'{idx=} was fixed with adding square brackets')\n",
    "        if isinstance(pred, dict):\n",
    "            print(f'{idx=} was a dict, we made it a list')\n",
    "            pred = [pred]\n",
    "    except:\n",
    "        print(f'{idx} is not proper json.\\n{pred}')\n",
    "        pred = []\n",
    "\n",
    "    all_preds[curr_sample['id']] = pred\n",
    "\n",
    "    t = {curr_sample['id']: curr_sample['expected_orders']}\n",
    "    p = {curr_sample['id']: pred}\n",
    "    metrics = evaluate_sample(t, p)\n",
    "    metricstr = f\"Desc F1:{metrics['description']['Rouge1_f1']:.3f} ({metrics['description']['Rouge1_recall']:.3f}/{metrics['description']['Rouge1_precision']:.3f})\"\n",
    "    metricstr += f\"  Reas F1:{metrics['reason']['Rouge1_f1']:.3f} ({metrics['reason']['Rouge1_recall']:.3f}/{metrics['reason']['Rouge1_precision']:.3f})\"\n",
    "    metricstr += f\"  OTyp F1:{metrics['order_type']['Strict_f1']:.3f} ({metrics['order_type']['Strict_recall']:.3f}/{metrics['order_type']['Strict_precision']:.3f})\"\n",
    "    metricstr += f\"  Prov F1:{metrics['provenance']['MultiLabel_f1']:.3f} ({metrics['provenance']['MultiLabel_recall']:.3f}/{metrics['provenance']['MultiLabel_precision']:.3f})\"\n",
    "    \n",
    "    print(metricstr)\n",
    "    all_metrics[curr_sample['id']] = metrics\n",
    "    metrics_per_sample[curr_sample['id']] = [metrics['description']['Rouge1_f1'], \n",
    "                                             metrics['reason']['Rouge1_f1'],\n",
    "                                             metrics['order_type']['Strict_f1'],\n",
    "                                             metrics['provenance']['MultiLabel_f1'],\n",
    "                                             curr_time,\n",
    "                                             len(pred),\n",
    "                                             len(curr_sample['expected_orders']),\n",
    "                                            ]\n",
    "    print()\n",
    "\n",
    "print('Done')\n",
    "# 'dev_ALL_qw14BUDQ4KXL_v5dot6_ex_specdec'\n",
    "# with open('data/dev_ALL_qw8BQ5KM_v5dot6_ex_specdec_v2c.json', 'w') as f:\n",
    "#     json.dump(all_preds, f)\n",
    "with open('data/dev_ALL_qw14BXLQ5_v5dot6_ex_specdec_v2c.json', 'w') as f:\n",
    "    json.dump(all_preds, f)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(metrics_per_sample).T\n",
    "df.columns = ['descF1', 'reasonF1', 'ordertypeF1', 'provF1', 'processingtime', 'len_pred', 'len_target']\n",
    "df['avg'] = df[['descF1', 'reasonF1', 'ordertypeF1', 'provF1']].mean(axis=1)\n",
    "print(df.mean(axis=0).round(3))\n",
    "df.round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30c68f-b328-4372-9600-dff0137bf5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377527a9-4473-41c8-94c2-050715fc04bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "181c910f-a844-47e5-821d-a3f85315f65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/g/ProjectsOverflow/MEDIQA/mediqa-oe/evaluation\n",
      "/mnt/g/ProjectsOverflow/MEDIQA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f939f30fd7446b1b5b38e0dd170c484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx=0: 13.1717s #targets=2 #preds=2 #tokens=13023 acibench_D2N182_virtscribe_clef_taskC_test3\n",
      "DescF1:0.190 (0.250/0.154)  ReasF1:0.107 (0.375/0.062)  OTypF1:0.500 (0.500/0.500)  ProvF1:0.250 (0.333/0.200)\n",
      "idx=1: 5.5012s #targets=3 #preds=3 #tokens=10253 acibench_D2N174_virtassist_clef_taskC_test3\n",
      "DescF1:0.909 (0.833/1.000)  ReasF1:0.333 (0.333/0.333)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.407 (0.611/0.306)\n",
      "idx=2: 4.9969s #targets=1 #preds=2 #tokens=10336 primock57_5_12\n",
      "DescF1:0.667 (1.000/0.500)  ReasF1:0.057 (1.000/0.029)  OTypF1:0.667 (1.000/0.500)  ProvF1:0.500 (0.500/0.500)\n",
      "idx=3: 7.3529s #targets=2 #preds=4 #tokens=11598 acibench_D2N140_virtscribe_clinicalnlp_taskC_test2\n",
      "DescF1:0.553 (0.717/0.450)  ReasF1:0.021 (0.500/0.011)  OTypF1:0.667 (1.000/0.500)  ProvF1:0.154 (0.200/0.125)\n",
      "idx=4: 5.0602s #targets=2 #preds=4 #tokens=10292 acibench_D2N067_aci_train\n",
      "DescF1:0.667 (1.000/0.500)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.667 (1.000/0.500)  ProvF1:0.600 (0.750/0.500)\n",
      "idx=5: 6.0899s #targets=1 #preds=1 #tokens=12015 primock57_4_1\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=6: 6.1819s #targets=3 #preds=4 #tokens=10806 acibench_D2N177_virtassist_clef_taskC_test3\n",
      "DescF1:0.733 (0.717/0.750)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.857 (1.000/0.750)  ProvF1:0.574 (0.833/0.438)\n",
      "idx=7: 4.8922s #targets=3 #preds=5 #tokens=9701 acibench_D2N136_virtassist_clinicalnlp_taskC_test2\n",
      "DescF1:0.750 (1.000/0.600)  ReasF1:0.621 (1.000/0.450)  OTypF1:0.750 (1.000/0.600)  ProvF1:0.625 (0.833/0.500)\n",
      "idx=8: 5.3621s #targets=1 #preds=3 #tokens=10496 acibench_D2N089_virtassist_clinicalnlp_taskB_test1\n",
      "DescF1:0.500 (1.000/0.333)  ReasF1:0.125 (1.000/0.067)  OTypF1:0.500 (1.000/0.333)  ProvF1:0.250 (0.500/0.167)\n",
      "9 is not proper json.\n",
      "[{\"order_type\": \"imaging\", \"description\": \"x-ray of your ankle\", \"reason\": \"you do have some tenderness over this bone and i'm sometimes worried about a fracture\", \"provenance\": [32]}, {\"order_type\": \"medication\", \"description\": \"naprosyn five hundred milligrams twice a day for pain control\", \"reason\": \"ankle sprain\", \"provenance\": [32]}, {\"order_type\": \"lab\", \"description\": \"hemoglobin a1c\", \"reason\": None, \"provenance\": [37]}, {\"order_type\": \"medication\", \"description\": \"refill norvasc\", \"reason\": None, \"provenance\": [32]}]\n",
      "idx=9: 3.3695s #targets=4 #preds=0 #tokens=8893 acibench_D2N109_aci_clinicalnlp_taskB_test1\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=10: 5.1265s #targets=3 #preds=3 #tokens=11136 acibench_D2N002_virtassist_train\n",
      "DescF1:1.000 (1.000/1.000)  ReasF1:0.500 (0.571/0.444)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.615 (0.444/1.000)\n",
      "11 is not proper json.\n",
      "[{\"order_type\": \"medication\", \"description\": \"increase lasix to 80 mg once a day\", \"reason\": \"you're retaining fluid\", \"provenance\": [115]}, {\"order_type\": \"imaging\", \"description\": \"echocardiogram\", \"reason\": None, \"provenance\": [120, 122]}]\n",
      "idx=11: 4.9114s #targets=1 #preds=0 #tokens=10923 acibench_D2N068_virtassist_valid\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=12: 4.1153s #targets=2 #preds=3 #tokens=9247 acibench_D2N061_aci_train\n",
      "DescF1:0.380 (0.575/0.283)  ReasF1:0.172 (0.385/0.111)  OTypF1:0.800 (1.000/0.667)  ProvF1:0.800 (1.000/0.667)\n",
      "idx=13: 4.7747s #targets=2 #preds=2 #tokens=10531 acibench_D2N010_virtassist_train\n",
      "DescF1:0.824 (1.000/0.700)  ReasF1:0.250 (0.500/0.167)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.600 (0.750/0.500)\n",
      "idx=14: 2.7507s #targets=2 #preds=2 #tokens=8841 acibench_D2N150_aci_clinicalnlp_taskC_test2\n",
      "DescF1:0.889 (1.000/0.800)  ReasF1:0.706 (0.750/0.667)  OTypF1:1.000 (1.000/1.000)  ProvF1:1.000 (1.000/1.000)\n",
      "idx=15: 6.3400s #targets=5 #preds=6 #tokens=10087 acibench_D2N164_aci_clinicalnlp_taskC_test2\n",
      "DescF1:0.599 (0.647/0.558)  ReasF1:0.101 (0.225/0.065)  OTypF1:0.909 (1.000/0.833)  ProvF1:0.571 (0.500/0.667)\n",
      "idx=16: 5.8296s #targets=2 #preds=2 #tokens=11475 acibench_D2N090_virtassist_clinicalnlp_taskB_test1\n",
      "DescF1:0.750 (0.667/0.857)  ReasF1:0.000 (0.000/0.000)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.500 (0.750/0.375)\n",
      "idx=17: 6.1413s #targets=4 #preds=4 #tokens=10999 acibench_D2N130_virtassist_clinicalnlp_taskC_test2\n",
      "DescF1:0.708 (0.708/0.708)  ReasF1:0.571 (0.667/0.500)  OTypF1:0.750 (0.750/0.750)  ProvF1:0.420 (0.292/0.750)\n",
      "idx=18: 3.1203s #targets=2 #preds=2 #tokens=8536 acibench_D2N053_aci_train\n",
      "DescF1:0.098 (0.065/0.200)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.500 (0.500/0.500)  ProvF1:0.400 (0.500/0.333)\n",
      "idx=19: 3.3661s #targets=4 #preds=4 #tokens=8526 acibench_D2N038_aci_train\n",
      "DescF1:0.669 (0.604/0.750)  ReasF1:0.280 (0.417/0.211)  OTypF1:0.750 (0.750/0.750)  ProvF1:0.750 (0.750/0.750)\n",
      "idx=20: 3.9183s #targets=3 #preds=2 #tokens=9209 acibench_D2N104_virtscribe_clinicalnlp_taskB_test1\n",
      "DescF1:0.455 (0.500/0.417)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.400 (0.333/0.500)  ProvF1:0.480 (0.667/0.375)\n",
      "idx=21: 2.3115s #targets=3 #preds=1 #tokens=8684 acibench_D2N054_aci_train\n",
      "DescF1:0.200 (0.111/1.000)  ReasF1:1.000 (1.000/1.000)  OTypF1:0.500 (0.333/1.000)  ProvF1:0.500 (0.333/1.000)\n",
      "22 is not proper json.\n",
      "[{\"order_type\": \"medication\", \"description\": \"Zantac twice a day\", \"reason\": \"acute gastritis and this is probably related to the caffeine intake\", \"provenance\": [33]}, {\"order_type\": \"lab\", \"description\": \"urinalysis\", \"reason\": \"to be sure it's nothing else going on\", \"provenance\": [33]}, {\"order_type\": \"lab\", \"description\": \"urine pregnancy test\", \"reason\": \"to be sure it's nothing else going on\", \"provenance\": [33]}, {\"order_type\": \"lab\", \"description\": \"cbc\", \"reason\": \"to be sure it's nothing else going on\", \"provenance\": [33]}, {\"order_type\": \"lab\", \"description\": \"comprehensive metabolic panel\", \"reason\": \"to be sure it's nothing else going on\", \"provenance\": [33]}, {\"order_type\": \"followup\", \"description\": \"follow up in four weeks\", \"reason\": None, \"provenance\": [33]}, {\"order_type\": \"medication\", \"description\": \"metformin one thousand milligrams in the morning and five hundred milligrams in the evening\", \"reason\": \"continue you on the metformin\", \"provenance\": [33]}]\n",
      "idx=22: 4.9852s #targets=8 #preds=0 #tokens=9207 acibench_D2N158_aci_clinicalnlp_taskC_test2\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=23: 10.5790s #targets=1 #preds=3 #tokens=13867 primock57_4_7\n",
      "DescF1:0.500 (1.000/0.333)  ReasF1:0.138 (1.000/0.074)  OTypF1:0.500 (1.000/0.333)  ProvF1:0.400 (0.500/0.333)\n",
      "idx=24: 2.9833s #targets=5 #preds=5 #tokens=7981 acibench_D2N085_aci_valid\n",
      "DescF1:0.888 (0.867/0.910)  ReasF1:0.111 (0.182/0.080)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.947 (1.000/0.900)\n",
      "idx=25: 3.5947s #targets=1 #preds=3 #tokens=8591 acibench_D2N124_aci_clinicalnlp_taskB_test1\n",
      "DescF1:0.500 (1.000/0.333)  ReasF1:0.091 (1.000/0.048)  OTypF1:0.500 (1.000/0.333)  ProvF1:0.500 (1.000/0.333)\n",
      "idx=26: 8.2652s #targets=1 #preds=1 #tokens=14289 primock57_1_14\n",
      "DescF1:1.000 (1.000/1.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.500 (0.333/1.000)\n",
      "idx=27: 3.7103s #targets=2 #preds=2 #tokens=9715 acibench_D2N119_aci_clinicalnlp_taskB_test1\n",
      "DescF1:0.500 (0.500/0.500)  ReasF1:0.353 (1.000/0.214)  OTypF1:0.500 (0.500/0.500)  ProvF1:0.333 (0.250/0.500)\n",
      "idx=28: 4.2540s #targets=2 #preds=2 #tokens=10146 acibench_D2N014_virtassist_train\n",
      "DescF1:1.000 (1.000/1.000)  ReasF1:0.263 (0.227/0.312)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.455 (0.417/0.500)\n",
      "29 is not proper json.\n",
      "[{\"order_type\": \"medication\", \"description\": \"refill metoprolol\", \"reason\": None, \"provenance\": [45]}, {\"order_type\": \"medication\", \"description\": \"refill crestor forty milligrams once a day\", \"reason\": None, \"provenance\": [45]}, {\"order_type\": \"medication\", \"description\": \"refill aspirin\", \"reason\": None, \"provenance\": [45]}, {\"order_type\": \"followup\", \"description\": \"appointment with nephrologist\", \"reason\": \"you do have the stage three ckd\", \"provenance\": [49]}, {\"order_type\": \"lab\", \"description\": \"hemoglobin a1c\", \"reason\": \"i'm gon na order another hemoglobin a1c\", \"provenance\": [51]}, {\"order_type\": \"followup\", \"description\": \"referral to psychiatry\", \"reason\": \"difficulty adjusting after having a heart attack maybe some some mild depression\", \"provenance\": [63]}]\n",
      "idx=29: 5.9789s #targets=5 #preds=0 #tokens=10264 acibench_D2N157_aci_clinicalnlp_taskC_test2\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=30: 7.9671s #targets=2 #preds=2 #tokens=12569 acibench_D2N026_virtscribe_train\n",
      "DescF1:0.395 (0.417/0.375)  ReasF1:0.230 (0.233/0.227)  OTypF1:0.500 (0.500/0.500)  ProvF1:0.125 (0.125/0.125)\n",
      "idx=31: 8.7074s #targets=2 #preds=2 #tokens=12328 primock57_5_4\n",
      "DescF1:0.400 (0.333/0.500)  ReasF1:0.167 (1.000/0.091)  OTypF1:0.500 (0.500/0.500)  ProvF1:0.200 (0.250/0.167)\n",
      "idx=32: 6.2129s #targets=0 #preds=7 #tokens=9276 acibench_D2N065_aci_train\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=33: 4.4707s #targets=4 #preds=4 #tokens=9463 acibench_D2N080_aci_valid\n",
      "DescF1:0.933 (0.875/1.000)  ReasF1:0.245 (0.500/0.163)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.933 (0.875/1.000)\n",
      "idx=34: 7.4400s #targets=1 #preds=4 #tokens=12203 primock57_1_1\n",
      "DescF1:0.400 (1.000/0.250)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.400 (1.000/0.250)  ProvF1:0.333 (0.500/0.250)\n",
      "idx=35: 5.6013s #targets=4 #preds=7 #tokens=9302 acibench_D2N189_aci_clef_taskC_test3\n",
      "DescF1:0.308 (0.240/0.429)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.545 (0.750/0.429)  ProvF1:0.508 (0.625/0.429)\n",
      "idx=36: 2.6972s #targets=1 #preds=1 #tokens=9114 acibench_D2N092_virtassist_clinicalnlp_taskB_test1\n",
      "DescF1:1.000 (1.000/1.000)  ReasF1:0.167 (0.500/0.100)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.667 (0.500/1.000)\n",
      "idx=37: 5.9504s #targets=5 #preds=3 #tokens=10867 acibench_D2N023_virtscribe_train\n",
      "DescF1:0.319 (0.190/1.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.750 (0.600/1.000)  ProvF1:0.211 (0.200/0.222)\n",
      "idx=38: 6.5649s #targets=4 #preds=3 #tokens=11936 primock57_1_8\n",
      "DescF1:0.571 (0.500/0.667)  ReasF1:0.077 (0.071/0.083)  OTypF1:0.571 (0.500/0.667)  ProvF1:0.480 (0.375/0.667)\n",
      "idx=39: 6.4741s #targets=2 #preds=5 #tokens=11041 acibench_D2N008_virtassist_train\n",
      "DescF1:0.571 (1.000/0.400)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.571 (1.000/0.400)  ProvF1:0.522 (0.750/0.400)\n",
      "idx=40: 2.9176s #targets=1 #preds=1 #tokens=9308 acibench_D2N102_virtscribe_clinicalnlp_taskB_test1\n",
      "DescF1:0.364 (0.400/0.333)  ReasF1:0.000 (0.000/0.000)  OTypF1:1.000 (1.000/1.000)  ProvF1:1.000 (1.000/1.000)\n",
      "idx=41: 9.7463s #targets=5 #preds=5 #tokens=13612 primock57_1_13\n",
      "DescF1:0.667 (0.660/0.675)  ReasF1:0.477 (0.750/0.350)  OTypF1:0.800 (0.800/0.800)  ProvF1:0.444 (0.500/0.400)\n",
      "idx=42: 4.0546s #targets=4 #preds=3 #tokens=9876 acibench_D2N183_virtscribe_clef_taskC_test3\n",
      "DescF1:0.621 (0.688/0.567)  ReasF1:0.424 (0.500/0.368)  OTypF1:0.857 (0.750/1.000)  ProvF1:0.356 (0.217/1.000)\n",
      "idx=43: 6.7362s #targets=4 #preds=9 #tokens=9524 acibench_D2N156_aci_clinicalnlp_taskC_test2\n",
      "DescF1:0.308 (0.500/0.222)  ReasF1:0.229 (0.236/0.222)  OTypF1:0.308 (0.500/0.222)  ProvF1:0.370 (0.417/0.333)\n",
      "idx=44: 8.3497s #targets=4 #preds=1 #tokens=14053 primock57_3_3\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=45: 5.7101s #targets=1 #preds=2 #tokens=11205 primock57_4_4\n",
      "DescF1:0.667 (1.000/0.500)  ReasF1:0.085 (0.182/0.056)  OTypF1:0.667 (1.000/0.500)  ProvF1:0.400 (1.000/0.250)\n",
      "idx=46: 5.3177s #targets=3 #preds=3 #tokens=10237 acibench_D2N015_virtassist_train\n",
      "DescF1:0.875 (1.000/0.778)  ReasF1:0.000 (0.000/0.000)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.628 (0.722/0.556)\n",
      "idx=47: 2.2349s #targets=2 #preds=1 #tokens=8461 acibench_D2N060_aci_train\n",
      "DescF1:0.125 (0.167/0.100)  ReasF1:0.609 (1.000/0.438)  OTypF1:0.667 (0.500/1.000)  ProvF1:0.667 (0.500/1.000)\n",
      "idx=48: 4.1226s #targets=4 #preds=4 #tokens=8869 acibench_D2N113_aci_clinicalnlp_taskB_test1\n",
      "DescF1:0.614 (0.604/0.625)  ReasF1:0.207 (0.333/0.150)  OTypF1:0.750 (0.750/0.750)  ProvF1:0.750 (0.750/0.750)\n",
      "idx=49: 6.7705s #targets=0 #preds=2 #tokens=12026 acibench_D2N030_virtscribe_train\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=50: 4.6905s #targets=1 #preds=3 #tokens=10128 acibench_D2N173_virtassist_clef_taskC_test3\n",
      "DescF1:0.364 (1.000/0.222)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.400 (0.500/0.333)\n",
      "idx=51: 5.5206s #targets=6 #preds=6 #tokens=9421 acibench_D2N149_aci_clinicalnlp_taskC_test2\n",
      "DescF1:0.609 (0.667/0.561)  ReasF1:0.212 (0.208/0.215)  OTypF1:0.667 (0.667/0.667)  ProvF1:0.667 (0.667/0.667)\n",
      "idx=52: 6.2628s #targets=0 #preds=1 #tokens=13213 acibench_D2N101_virtscribe_clinicalnlp_taskB_test1\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=53: 3.4462s #targets=2 #preds=2 #tokens=9320 acibench_D2N148_aci_clinicalnlp_taskC_test2\n",
      "DescF1:1.000 (1.000/1.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.750 (0.750/0.750)\n",
      "idx=54: 4.1471s #targets=1 #preds=1 #tokens=10872 primock57_3_1\n",
      "DescF1:1.000 (1.000/1.000)  ReasF1:0.211 (0.667/0.125)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.400 (0.500/0.333)\n",
      "idx=55: 5.3519s #targets=3 #preds=4 #tokens=9928 acibench_D2N012_virtassist_train\n",
      "DescF1:0.571 (0.667/0.500)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.571 (0.667/0.500)  ProvF1:0.437 (0.389/0.500)\n",
      "idx=56: 9.6425s #targets=5 #preds=7 #tokens=11838 acibench_D2N027_virtscribe_train\n",
      "DescF1:0.431 (0.433/0.429)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.500 (0.600/0.429)  ProvF1:0.317 (0.400/0.262)\n",
      "idx=57: 9.0980s #targets=2 #preds=3 #tokens=12278 acibench_D2N099_virtscribe_clinicalnlp_taskB_test1\n",
      "DescF1:0.195 (0.286/0.148)  ReasF1:0.091 (0.250/0.056)  OTypF1:0.400 (0.500/0.333)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=58: 3.9641s #targets=2 #preds=3 #tokens=9496 acibench_D2N059_aci_train\n",
      "DescF1:0.615 (0.800/0.500)  ReasF1:0.053 (0.500/0.028)  OTypF1:0.800 (1.000/0.667)  ProvF1:0.706 (0.750/0.667)\n",
      "idx=59: 5.8237s #targets=1 #preds=2 #tokens=11512 primock57_4_3\n",
      "DescF1:0.636 (0.875/0.500)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.667 (1.000/0.500)  ProvF1:0.400 (1.000/0.250)\n",
      "idx=60: 3.3486s #targets=1 #preds=3 #tokens=8704 acibench_D2N107_aci_clinicalnlp_taskB_test1\n",
      "DescF1:0.500 (1.000/0.333)  ReasF1:0.471 (0.800/0.333)  OTypF1:0.500 (1.000/0.333)  ProvF1:0.500 (1.000/0.333)\n",
      "idx=61: 5.9661s #targets=0 #preds=2 #tokens=12355 primock57_4_5\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=62: 4.9400s #targets=5 #preds=5 #tokens=10162 acibench_D2N152_aci_clinicalnlp_taskC_test2\n",
      "DescF1:0.692 (0.800/0.610)  ReasF1:0.442 (0.600/0.350)  OTypF1:0.600 (0.600/0.600)  ProvF1:0.800 (0.800/0.800)\n",
      "idx=63: 6.5114s #targets=2 #preds=2 #tokens=12406 primock57_1_15\n",
      "DescF1:0.645 (0.958/0.487)  ReasF1:0.000 (0.000/0.000)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.737 (1.000/0.583)\n",
      "idx=64: 3.5502s #targets=1 #preds=2 #tokens=8861 acibench_D2N126_aci_clinicalnlp_taskB_test1\n",
      "DescF1:0.571 (0.667/0.500)  ReasF1:0.016 (0.333/0.008)  OTypF1:0.667 (1.000/0.500)  ProvF1:0.333 (0.500/0.250)\n",
      "65 is not proper json.\n",
      "[{\"order_type\": \"medication\", \"description\": \"prozac 40 milligrams once a day\", \"reason\": \"i think the , the medication has helped me in the past , and maybe just increasing the dose might help me through this patch\", \"provenance\": [26, 79, 80]}, {\"order_type\": \"medication\", \"description\": \"aspirin 81 milligrams daily\", \"reason\": None, \"provenance\": [86]}, {\"order_type\": \"imaging\", \"description\": \"echocardiogram\", \"reason\": None, \"provenance\": [86]}, {\"order_type\": \"followup\", \"description\": \"physical therapy referral\", \"reason\": None, \"provenance\": [78]}]\n",
      "idx=65: 4.6961s #targets=3 #preds=0 #tokens=9941 acibench_D2N007_virtassist_train\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=66: 9.5170s #targets=2 #preds=3 #tokens=14849 acibench_D2N185_virtscribe_clef_taskC_test3\n",
      "DescF1:0.123 (0.417/0.072)  ReasF1:0.210 (0.212/0.208)  OTypF1:0.800 (1.000/0.667)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=67: 5.5805s #targets=5 #preds=2 #tokens=11562 primock57_5_9\n",
      "DescF1:0.306 (0.300/0.312)  ReasF1:0.034 (0.250/0.019)  OTypF1:0.571 (0.400/1.000)  ProvF1:0.286 (0.167/1.000)\n",
      "68 is not proper json.\n",
      "[{\"order_type\": \"medication\", \"description\": \"ibuprofen as needed\", \"reason\": \"to help with any pain and that's also gon na help reduce that inflammation and swelling\", \"provenance\": [35]}, {\"order_type\": \"followup\", \"description\": \"follow up in fourteen days\", \"reason\": \"your symptoms should significantly improve over a few weeks but i'd like to follow up with you and see how you're doing\", \"provenance\": [35]}, {\"order_type\": \"imaging\", \"description\": \"x-ray of right ankle\", \"reason\": None, \"provenance\": [33]}, {\"order_type\": \"medication\", \"description\": \"air cast\", \"reason\": \"the best treatment at this time for your sprain is to keep your leg elevated when you're seated and let's continue to ice\", \"provenance\": [33]}, {\"order_type\": \"medication\", \"description\": \"crutches\", \"reason\": \"i want you to stay off that leg and start walking on it stay off your leg for now and then in a couple of days start walking on it as tolerated\", \"provenance\": [33]}]\n",
      "idx=68: 4.3225s #targets=1 #preds=0 #tokens=8798 acibench_D2N042_aci_train\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "69 is not proper json.\n",
      "[{\"order_type\": \"medication\", \"description\": \"tramadol 50 milligrams\", \"reason\": \"you said for you\", \"provenance\": [39]}, {\"order_type\": \"lab\", \"description\": \"bmp\", \"reason\": None, \"provenance\": [41]}, {\"order_type\": \"lab\", \"description\": \"urinalysis\", \"reason\": None, \"provenance\": [41]}, {\"order_type\": \"lab\", \"description\": \"urine culture\", \"reason\": None, \"provenance\": [41]}]\n",
      "idx=69: 3.3795s #targets=6 #preds=0 #tokens=9063 acibench_D2N206_aci_clef_taskC_test3\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=70: 7.3274s #targets=4 #preds=3 #tokens=12938 primock57_1_10\n",
      "DescF1:0.639 (0.542/0.778)  ReasF1:0.077 (0.125/0.056)  OTypF1:0.857 (0.750/1.000)  ProvF1:0.545 (0.375/1.000)\n",
      "idx=71: 7.1196s #targets=4 #preds=3 #tokens=12569 acibench_D2N028_virtscribe_train\n",
      "DescF1:0.689 (0.525/1.000)  ReasF1:0.154 (0.250/0.111)  OTypF1:0.857 (0.750/1.000)  ProvF1:0.284 (0.208/0.444)\n",
      "idx=72: 3.7162s #targets=1 #preds=1 #tokens=9751 acibench_D2N098_virtscribe_clinicalnlp_taskB_test1\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=73: 4.3482s #targets=1 #preds=5 #tokens=8961 acibench_D2N167_aci_clinicalnlp_taskC_test2\n",
      "DescF1:0.278 (0.833/0.167)  ReasF1:0.024 (0.333/0.013)  OTypF1:0.333 (1.000/0.200)  ProvF1:0.286 (0.500/0.200)\n",
      "idx=74: 3.5422s #targets=3 #preds=2 #tokens=9187 acibench_D2N043_aci_train\n",
      "DescF1:0.265 (0.156/0.875)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.800 (0.667/1.000)  ProvF1:0.645 (0.667/0.625)\n",
      "idx=75: 7.0927s #targets=0 #preds=3 #tokens=12359 acibench_D2N022_virtscribe_train\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "76 is not proper json.\n",
      "[{\"order_type\": \"medication\", \"description\": \"meloxicam 15 milligrams once a day\", \"reason\": \"lumbar strain\", \"provenance\": [110, 111]}, {\"order_type\": \"medication\", \"description\": \"lisinopril 10 milligrams po daily\", \"reason\": None, \"provenance\": [118, 125, 126]}]\n",
      "idx=76: 4.8750s #targets=2 #preds=0 #tokens=10666 acibench_D2N095_virtassist_clinicalnlp_taskB_test1\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=77: 4.0639s #targets=3 #preds=4 #tokens=8783 acibench_D2N197_aci_clef_taskC_test3\n",
      "DescF1:0.696 (0.704/0.688)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.857 (1.000/0.750)  ProvF1:0.556 (0.500/0.625)\n",
      "idx=78: 3.4947s #targets=1 #preds=1 #tokens=10211 acibench_D2N103_virtscribe_clinicalnlp_taskB_test1\n",
      "DescF1:0.833 (1.000/0.714)  ReasF1:0.000 (0.000/0.000)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.667 (1.000/0.500)\n",
      "idx=79: 5.5337s #targets=2 #preds=2 #tokens=12081 primock57_3_7\n",
      "DescF1:0.500 (0.500/0.500)  ReasF1:0.200 (0.167/0.250)  OTypF1:0.500 (0.500/0.500)  ProvF1:0.250 (0.250/0.250)\n",
      "idx=80: 2.5850s #targets=2 #preds=2 #tokens=8594 acibench_D2N204_aci_clef_taskC_test3\n",
      "DescF1:0.963 (0.929/1.000)  ReasF1:0.632 (0.667/0.600)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.857 (0.750/1.000)\n",
      "idx=81: 8.8300s #targets=9 #preds=8 #tokens=11513 acibench_D2N088_virtassist_clinicalnlp_taskB_test1\n",
      "DescF1:0.819 (0.778/0.865)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.941 (0.889/1.000)  ProvF1:0.693 (0.722/0.667)\n",
      "82 is not proper json.\n",
      "[{\"order_type\": \"medication\", \"description\": \"protonix 40 milligrams once a day\", \"reason\": \"newfound anemia and for that , i think that we should go ahead and put you on protonix , 40 milligrams , once a day to help with the gastritis\", \"provenance\": [82, 90]}, {\"order_type\": \"lab\", \"description\": \"complete blood count\", \"reason\": None, \"provenance\": [102, 103]}]\n",
      "idx=82: 4.1189s #targets=2 #preds=0 #tokens=9933 acibench_D2N020_virtassist_train\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=83: 6.7757s #targets=1 #preds=8 #tokens=10140 acibench_D2N146_aci_clinicalnlp_taskC_test2\n",
      "DescF1:0.069 (1.000/0.036)  ReasF1:0.024 (0.333/0.013)  OTypF1:0.222 (1.000/0.125)  ProvF1:0.222 (1.000/0.125)\n",
      "idx=84: 6.8767s #targets=4 #preds=5 #tokens=10904 acibench_D2N118_aci_clinicalnlp_taskB_test1\n",
      "DescF1:0.594 (0.625/0.567)  ReasF1:0.093 (0.667/0.050)  OTypF1:0.667 (0.750/0.600)  ProvF1:0.429 (0.333/0.600)\n",
      "idx=85: 8.4710s #targets=5 #preds=2 #tokens=12992 primock57_1_3\n",
      "DescF1:0.105 (0.200/0.071)  ReasF1:0.227 (0.167/0.357)  OTypF1:0.286 (0.200/0.500)  ProvF1:0.143 (0.100/0.250)\n",
      "idx=86: 7.5957s #targets=0 #preds=2 #tokens=13080 primock57_4_6\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=87: 7.6267s #targets=2 #preds=4 #tokens=11807 acibench_D2N190_aci_clef_taskC_test3\n",
      "DescF1:0.481 (0.619/0.393)  ReasF1:0.121 (1.000/0.065)  OTypF1:0.667 (1.000/0.500)  ProvF1:0.500 (0.750/0.375)\n",
      "idx=88: 7.1755s #targets=2 #preds=1 #tokens=13453 acibench_D2N105_virtscribe_clinicalnlp_taskB_test1\n",
      "DescF1:0.222 (0.125/1.000)  ReasF1:0.083 (0.167/0.056)  OTypF1:0.667 (0.500/1.000)  ProvF1:0.200 (0.167/0.250)\n",
      "idx=89: 2.4776s #targets=1 #preds=1 #tokens=9060 primock57_3_6\n",
      "DescF1:1.000 (1.000/1.000)  ReasF1:0.133 (0.167/0.111)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.500 (0.500/0.500)\n",
      "idx=90: 7.5687s #targets=4 #preds=5 #tokens=11333 acibench_D2N151_aci_clinicalnlp_taskC_test2\n",
      "DescF1:0.575 (0.812/0.445)  ReasF1:0.501 (1.000/0.334)  OTypF1:0.889 (1.000/0.800)  ProvF1:0.702 (0.625/0.800)\n",
      "idx=91: 3.9273s #targets=1 #preds=1 #tokens=10260 primock57_3_8\n",
      "DescF1:0.889 (1.000/0.800)  ReasF1:0.571 (1.000/0.400)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.333 (0.500/0.250)\n",
      "idx=92: 2.8341s #targets=1 #preds=2 #tokens=8748 acibench_D2N034_aci_train\n",
      "DescF1:0.632 (0.857/0.500)  ReasF1:0.625 (1.000/0.455)  OTypF1:0.667 (1.000/0.500)  ProvF1:0.333 (0.500/0.250)\n",
      "idx=93: 4.9607s #targets=5 #preds=5 #tokens=9406 acibench_D2N040_aci_train\n",
      "DescF1:0.640 (0.533/0.800)  ReasF1:0.105 (0.250/0.067)  OTypF1:0.800 (0.800/0.800)  ProvF1:0.747 (0.700/0.800)\n",
      "idx=94: 3.7089s #targets=0 #preds=2 #tokens=9164 acibench_D2N044_aci_train\n",
      "DescF1:0.000 (0.000/0.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.000 (0.000/0.000)  ProvF1:0.000 (0.000/0.000)\n",
      "idx=95: 3.1033s #targets=2 #preds=1 #tokens=9250 acibench_D2N125_aci_clinicalnlp_taskB_test1\n",
      "DescF1:0.667 (0.500/1.000)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.667 (0.500/1.000)  ProvF1:0.222 (0.250/0.200)\n",
      "idx=96: 6.0528s #targets=6 #preds=5 #tokens=10573 acibench_D2N199_aci_clef_taskC_test3\n",
      "DescF1:0.892 (0.806/1.000)  ReasF1:0.200 (0.184/0.220)  OTypF1:0.909 (0.833/1.000)  ProvF1:0.909 (0.833/1.000)\n",
      "idx=97: 4.7178s #targets=1 #preds=1 #tokens=10985 primock57_5_5\n",
      "DescF1:0.857 (1.000/0.750)  ReasF1:0.963 (1.000/0.929)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.857 (1.000/0.750)\n",
      "idx=98: 8.1731s #targets=1 #preds=3 #tokens=13075 primock57_5_11\n",
      "DescF1:0.200 (0.250/0.167)  ReasF1:0.000 (0.000/0.000)  OTypF1:0.500 (1.000/0.333)  ProvF1:0.333 (0.333/0.333)\n",
      "idx=99: 5.6884s #targets=3 #preds=4 #tokens=10088 acibench_D2N191_aci_clef_taskC_test3\n",
      "DescF1:0.667 (0.778/0.583)  ReasF1:0.086 (1.000/0.045)  OTypF1:0.857 (1.000/0.750)  ProvF1:0.400 (0.333/0.500)\n",
      "Done\n",
      "descF1                0.475\n",
      "reasonF1              0.153\n",
      "ordertypeF1           0.583\n",
      "provF1                0.401\n",
      "processingtime        5.512\n",
      "len_pred              2.810\n",
      "len_target            2.550\n",
      "total_tokens      10615.080\n",
      "avg                   0.403\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descF1</th>\n",
       "      <th>reasonF1</th>\n",
       "      <th>ordertypeF1</th>\n",
       "      <th>provF1</th>\n",
       "      <th>processingtime</th>\n",
       "      <th>len_pred</th>\n",
       "      <th>len_target</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acibench_D2N182_virtscribe_clef_taskC_test3</th>\n",
       "      <td>0.190</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>13.172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13023.0</td>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acibench_D2N174_virtassist_clef_taskC_test3</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.407</td>\n",
       "      <td>5.501</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10253.0</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primock57_5_12</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>4.997</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10336.0</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acibench_D2N140_virtscribe_clinicalnlp_taskC_test2</th>\n",
       "      <td>0.553</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.154</td>\n",
       "      <td>7.353</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11598.0</td>\n",
       "      <td>0.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acibench_D2N067_aci_train</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.600</td>\n",
       "      <td>5.060</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10292.0</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acibench_D2N125_aci_clinicalnlp_taskB_test1</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.222</td>\n",
       "      <td>3.103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9250.0</td>\n",
       "      <td>0.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acibench_D2N199_aci_clef_taskC_test3</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.909</td>\n",
       "      <td>6.053</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10573.0</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primock57_5_5</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.963</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>4.718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10985.0</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primock57_5_11</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333</td>\n",
       "      <td>8.173</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13075.0</td>\n",
       "      <td>0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acibench_D2N191_aci_clef_taskC_test3</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.400</td>\n",
       "      <td>5.688</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10088.0</td>\n",
       "      <td>0.503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    descF1  reasonF1  \\\n",
       "acibench_D2N182_virtscribe_clef_taskC_test3          0.190     0.107   \n",
       "acibench_D2N174_virtassist_clef_taskC_test3          0.909     0.333   \n",
       "primock57_5_12                                       0.667     0.057   \n",
       "acibench_D2N140_virtscribe_clinicalnlp_taskC_test2   0.553     0.021   \n",
       "acibench_D2N067_aci_train                            0.667     0.000   \n",
       "...                                                    ...       ...   \n",
       "acibench_D2N125_aci_clinicalnlp_taskB_test1          0.667     0.000   \n",
       "acibench_D2N199_aci_clef_taskC_test3                 0.892     0.200   \n",
       "primock57_5_5                                        0.857     0.963   \n",
       "primock57_5_11                                       0.200     0.000   \n",
       "acibench_D2N191_aci_clef_taskC_test3                 0.667     0.086   \n",
       "\n",
       "                                                    ordertypeF1  provF1  \\\n",
       "acibench_D2N182_virtscribe_clef_taskC_test3               0.500   0.250   \n",
       "acibench_D2N174_virtassist_clef_taskC_test3               1.000   0.407   \n",
       "primock57_5_12                                            0.667   0.500   \n",
       "acibench_D2N140_virtscribe_clinicalnlp_taskC_test2        0.667   0.154   \n",
       "acibench_D2N067_aci_train                                 0.667   0.600   \n",
       "...                                                         ...     ...   \n",
       "acibench_D2N125_aci_clinicalnlp_taskB_test1               0.667   0.222   \n",
       "acibench_D2N199_aci_clef_taskC_test3                      0.909   0.909   \n",
       "primock57_5_5                                             1.000   0.857   \n",
       "primock57_5_11                                            0.500   0.333   \n",
       "acibench_D2N191_aci_clef_taskC_test3                      0.857   0.400   \n",
       "\n",
       "                                                    processingtime  len_pred  \\\n",
       "acibench_D2N182_virtscribe_clef_taskC_test3                 13.172       2.0   \n",
       "acibench_D2N174_virtassist_clef_taskC_test3                  5.501       3.0   \n",
       "primock57_5_12                                               4.997       2.0   \n",
       "acibench_D2N140_virtscribe_clinicalnlp_taskC_test2           7.353       4.0   \n",
       "acibench_D2N067_aci_train                                    5.060       4.0   \n",
       "...                                                            ...       ...   \n",
       "acibench_D2N125_aci_clinicalnlp_taskB_test1                  3.103       1.0   \n",
       "acibench_D2N199_aci_clef_taskC_test3                         6.053       5.0   \n",
       "primock57_5_5                                                4.718       1.0   \n",
       "primock57_5_11                                               8.173       3.0   \n",
       "acibench_D2N191_aci_clef_taskC_test3                         5.688       4.0   \n",
       "\n",
       "                                                    len_target  total_tokens  \\\n",
       "acibench_D2N182_virtscribe_clef_taskC_test3                2.0       13023.0   \n",
       "acibench_D2N174_virtassist_clef_taskC_test3                3.0       10253.0   \n",
       "primock57_5_12                                             1.0       10336.0   \n",
       "acibench_D2N140_virtscribe_clinicalnlp_taskC_test2         2.0       11598.0   \n",
       "acibench_D2N067_aci_train                                  2.0       10292.0   \n",
       "...                                                        ...           ...   \n",
       "acibench_D2N125_aci_clinicalnlp_taskB_test1                2.0        9250.0   \n",
       "acibench_D2N199_aci_clef_taskC_test3                       6.0       10573.0   \n",
       "primock57_5_5                                              1.0       10985.0   \n",
       "primock57_5_11                                             1.0       13075.0   \n",
       "acibench_D2N191_aci_clef_taskC_test3                       3.0       10088.0   \n",
       "\n",
       "                                                      avg  \n",
       "acibench_D2N182_virtscribe_clef_taskC_test3         0.262  \n",
       "acibench_D2N174_virtassist_clef_taskC_test3         0.662  \n",
       "primock57_5_12                                      0.473  \n",
       "acibench_D2N140_virtscribe_clinicalnlp_taskC_test2  0.349  \n",
       "acibench_D2N067_aci_train                           0.483  \n",
       "...                                                   ...  \n",
       "acibench_D2N125_aci_clinicalnlp_taskB_test1         0.389  \n",
       "acibench_D2N199_aci_clef_taskC_test3                0.728  \n",
       "primock57_5_5                                       0.919  \n",
       "primock57_5_11                                      0.258  \n",
       "acibench_D2N191_aci_clef_taskC_test3                0.503  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from llama_cpp import Llama, LlamaGrammar\n",
    "from llama_cpp.llama_speculative import LlamaPromptLookupDecoding\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%cd mediqa-oe/evaluation\n",
    "from evaluate_oe import evaluate_sample\n",
    "evaluate_sample\n",
    "%cd ../..\n",
    "\n",
    "with open('data/orders_data_transcript.json', 'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "allids = [_['id'] for _ in data['dev']]\n",
    "\n",
    "startmodelloading_time = time.time()\n",
    "\n",
    "mname = \"/home/justin/llama/Qwen3-14B-UD-Q4_K_XL.gguf\"\n",
    "try:\n",
    "    llm\n",
    "except NameError:\n",
    "    print('Loading model')\n",
    "    llm = Llama(\n",
    "        model_path=mname,  \n",
    "        draft_model=LlamaPromptLookupDecoding(),\n",
    "        logits_all=True,\n",
    "        n_gpu_layers=-1,\n",
    "        flash_attn=True,\n",
    "        # n_ctx=int(4096*5.7),\n",
    "        # n_ctx=int(4096*7),\n",
    "        n_ctx=int(4096*7),\n",
    "        verbose=False,\n",
    "        n_threads=os.cpu_count() - 2\n",
    "    )\n",
    "    print(f'Loaded model {time.time()-startmodelloading_time:.4f}s.')\n",
    "\n",
    "def shorten_transcript(s):\n",
    "    s = str(s)\n",
    "    s = s.replace('turn_id', 'turn').replace('DOCTOR', 'DOC').replace('PATIENT', 'PAT').replace('transcript', 'txt')\n",
    "    return s\n",
    "\n",
    "\n",
    "train_examples_predicted_turns = {\n",
    "    'acibench_D2N074_virtscribe_valid': [10, 14],\n",
    "    'primock57_2_6': [184, 185, 186, 189, 190, 180, 181, 183, 191, 192],\n",
    "    'acibench_D2N025_virtscribe_train': [80, 88, 90, 96, 133],\n",
    "    'primock57_1_2': [80, 88, 90, 96, 133],    \n",
    "}\n",
    "\n",
    "def get_salient_transcript(sample):\n",
    "    expected_output = sample['expected_orders']\n",
    "    transcript = sample['transcript']\n",
    "    salient_turns = [__ for _ in expected_output for __ in _['provenance']]\n",
    "    salient_turns += train_examples_predicted_turns[sample['id']]\n",
    "    salient_turns += [_-3 for _ in salient_turns]\n",
    "    salient_turns += [_-2 for _ in salient_turns]\n",
    "    salient_turns += [_-1 for _ in salient_turns]\n",
    "    salient_turns += [_+1 for _ in salient_turns]\n",
    "    salient_turns += [_+2 for _ in salient_turns]\n",
    "    salient_turns += [_+3 for _ in salient_turns]\n",
    "    salient_turns = sorted(set(salient_turns))\n",
    "    salient_transcript = [transcript[idx] for idx in salient_turns if idx<len(transcript)]\n",
    "    return salient_transcript\n",
    "\n",
    "examplestr = \\\n",
    "f\"\"\"\n",
    "EXAMPLE1START\n",
    "Transcript:\n",
    "{shorten_transcript(data['train'][0]['transcript'])}\n",
    "Desired output:\n",
    "{data['train'][0]['expected_orders']}\n",
    "EXAMPLE1END\n",
    "\n",
    "EXAMPLE2START\n",
    "Transcript:\n",
    "{shorten_transcript(data['train'][-1]['transcript'])}\n",
    "Desired output:\n",
    "{data['train'][-1]['expected_orders']}\n",
    "EXAMPLE2END\n",
    "\"\"\".replace('\\'', '\"')\n",
    "\n",
    "def get_train_sample_from_idname(idname):\n",
    "    return [_ for _ in data['train'] if idname in _['id']][0]\n",
    "\n",
    "example_transcripts = [get_salient_transcript(get_train_sample_from_idname(idname)) for idname in train_examples_predicted_turns]\n",
    "example_transcripts = [shorten_transcript(_) for _ in example_transcripts]\n",
    "example_outputs = [get_train_sample_from_idname(idname)['expected_orders'] for idname in train_examples_predicted_turns]\n",
    "\n",
    "examplestr = \"\".join([f\"EXAMPLE{idx+1}START\\nTranscript:\\n{transcript}\\nExpected output:\\n{output}\\n\" for idx, (transcript, output) in enumerate(zip(example_transcripts, example_outputs))]).replace('\\'', '\"')\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are an assistant for extracting medical orders from transcripts of patient doctor conversations.\n",
    "\n",
    "Medical order extraction involves identifying and structuring various medical orders —such as medications, imaging studies, lab tests, and follow-ups— based on doctor-patient conversations. \n",
    "\n",
    "The conversation is given to you in the format of a list of dicts with turn, speaker (doctor or patient), and txt for each turn.\n",
    "\n",
    "You are to return a list of dicts with these keys: order_type, description, reason, and provenance. \n",
    "\n",
    "1. Return a list with one dict for each order from the conversation. Your output will be parsed with json.loads().\n",
    "2. If there is only a single order, still return a list.\n",
    "3. There are only four allowed values for the order_type: \"medication\", \"lab\", \"followup\", \"imaging\"\n",
    "4. Provenance should be a list of ints relating to the turn ids that ground the order. This is the turn where the order was made, and maybe include directly preceeding turns where the reason was mentioned.\n",
    "5. Quote the reason verbatim from the text.\n",
    "6. Only list *new* or repeat orders. Do not list things that the patient is to continue doing that are mentioned in passing. Do not list previous exams.\n",
    "7. The above point (6.) is very important. Orders that have a \"continue\" status (e.g. \"we will continue with xanax XXmg\") are NOT considered valid orders, since we dont need to place a specific order in EHR for instance.\n",
    "8. Lab orders are fine-grained, i.e. each test is one order.\n",
    "9. If the doctor suggests an over the counter medication (e.g. pain killers), we also count that as an order - UNLESS the patient is already taking it (remember rule 6!)\n",
    "10. Only count orders that are actually made, not ones that are conditional (if your pain persists, maybe we...).\n",
    "\n",
    "Make sure your output is a list (i.e. starts and ends with square brackets) of dicts, separated by commas.\n",
    "\n",
    "Examples:\n",
    "{examplestr}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "data_to_use = [_ for _ in data['dev'] if _['id'] not in train_examples_predicted_turns]#data['train'][:]\n",
    "all_preds = {}\n",
    "all_metrics = {}\n",
    "metrics_per_sample = {}\n",
    "for idx, curr_sample in enumerate(tqdm(data_to_use)):\n",
    "    curr_sample = data_to_use[idx]\n",
    "    curr_transcript = shorten_transcript(curr_sample['transcript'])\n",
    "    \n",
    "    user_prompt = f\"Please process this transcript.\\nTRANSCRIPTSTART\\n{curr_transcript}\\nTRANSCRIPTEND\\nPlease follow all the rules and instructions carefully. Reply only with the valid response in the desired format.\"\n",
    "    prompt=f\"\"\"\n",
    "    <|im_start|>system{system_prompt}<|im_end|>\n",
    "    <|im_start|>user\\n{user_prompt} \\\\nothink<|im_end|>\n",
    "    <|im_start|>assistant\\n<think>\\n</think>\\n[\"\"\"\n",
    "    start = time.time()\n",
    "    response = llm.create_completion(\n",
    "        prompt=prompt,\n",
    "        max_tokens=int(4096*0.5),\n",
    "        temperature=0., top_k=1, top_p=1.0,\n",
    "        stop=[]\n",
    "    )\n",
    "    curr_time = time.time()-start\n",
    "    \n",
    "    pred = '['+response['choices'][0]['text']\n",
    "    if \"</think>\" in pred:\n",
    "        thought_trace = pred.split('</think>')[0]\n",
    "        print(thought_trace)\n",
    "        pred = pred.split('</think>')[-1]\n",
    "    try:\n",
    "        try:\n",
    "            pred = json.loads(pred)\n",
    "        except:\n",
    "            pred = json.loads('['+pred+']')\n",
    "            print(f'{idx=} was fixed with adding square brackets')\n",
    "        if isinstance(pred, dict):\n",
    "            print(f'{idx=} was a dict, we made it a list')\n",
    "            pred = [pred]\n",
    "    except:\n",
    "        print(f'{idx} is not proper json.\\n{pred}')\n",
    "        pred = []\n",
    "\n",
    "    all_preds[curr_sample['id']] = pred\n",
    "\n",
    "    t = {curr_sample['id']: curr_sample['expected_orders']}\n",
    "    p = {curr_sample['id']: pred}\n",
    "    metrics = evaluate_sample(t, p)\n",
    "    metricstr = f\"DescF1:{metrics['description']['Rouge1_f1']:.3f} ({metrics['description']['Rouge1_recall']:.3f}/{metrics['description']['Rouge1_precision']:.3f})\"\n",
    "    metricstr += f\"  ReasF1:{metrics['reason']['Rouge1_f1']:.3f} ({metrics['reason']['Rouge1_recall']:.3f}/{metrics['reason']['Rouge1_precision']:.3f})\"\n",
    "    metricstr += f\"  OTypF1:{metrics['order_type']['Strict_f1']:.3f} ({metrics['order_type']['Strict_recall']:.3f}/{metrics['order_type']['Strict_precision']:.3f})\"\n",
    "    metricstr += f\"  ProvF1:{metrics['provenance']['MultiLabel_f1']:.3f} ({metrics['provenance']['MultiLabel_recall']:.3f}/{metrics['provenance']['MultiLabel_precision']:.3f})\"\n",
    "\n",
    "    num_tokens = response['usage']['total_tokens']\n",
    "    num_targets = len(curr_sample['expected_orders'])\n",
    "    num_preds = len(pred)\n",
    "    print(f'{idx=}: {curr_time:.4f}s #targets={num_targets} #preds={num_preds} #tokens={num_tokens} {curr_sample[\"id\"]}')\n",
    "    \n",
    "    print(metricstr)\n",
    "    all_metrics[curr_sample['id']] = metrics\n",
    "    metrics_per_sample[curr_sample['id']] = [metrics['description']['Rouge1_f1'], \n",
    "                                             metrics['reason']['Rouge1_f1'],\n",
    "                                             metrics['order_type']['Strict_f1'],\n",
    "                                             metrics['provenance']['MultiLabel_f1'],\n",
    "                                             curr_time,\n",
    "                                             num_preds,\n",
    "                                             num_targets,\n",
    "                                             num_tokens,\n",
    "                                            ]\n",
    "    # print()\n",
    "\n",
    "print('Done')\n",
    "mname_short = mname.split('/')[-1].split('.gguf')[0].replace('Qwen','qw')\n",
    "savestr = f'dev_ALL_{mname_short}_shortenedexs'\n",
    "with open(f'data/{savestr}.json', 'w') as f:\n",
    "    json.dump(all_preds, f)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(metrics_per_sample).T\n",
    "df.columns = ['descF1', 'reasonF1', 'ordertypeF1', 'provF1', 'processingtime', 'len_pred', 'len_target', 'total_tokens']\n",
    "df['avg'] = df[['descF1', 'reasonF1', 'ordertypeF1', 'provF1']].mean(axis=1)\n",
    "print(df.mean(axis=0).round(3))\n",
    "df.round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c59a70-fe25-40ce-8cb1-f738e47d08b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (1412554130.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31midx=0: 11.2263s #targets=2 #preds=2 #tokens=13025 acibench_D2N182_virtscribe_clef_taskC_test3\u001b[39m\n                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "idx=0: 11.2263s #targets=2 #preds=2 #tokens=13025 acibench_D2N182_virtscribe_clef_taskC_test3\n",
    "DescF1:0.200 (0.250/0.167)  ReasF1:0.107 (0.375/0.062)  OTypF1:0.500 (0.500/0.500)  ProvF1:0.250 (0.333/0.200)\n",
    "idx=1: 3.7126s #targets=3 #preds=3 #tokens=10253 acibench_D2N174_virtassist_clef_taskC_test3\n",
    "DescF1:0.909 (0.833/1.000)  ReasF1:0.333 (0.333/0.333)  OTypF1:1.000 (1.000/1.000)  ProvF1:0.407 (0.611/0.306)\n",
    "idx=2: 2.7383s #targets=1 #preds=2 #tokens=10306 primock57_5_12\n",
    "DescF1:0.667 (1.000/0.500)  ReasF1:0.087 (1.000/0.045)  OTypF1:0.667 (1.000/0.500)  ProvF1:0.500 (0.500/0.500)\n",
    "idx=3: 4.8973s #targets=2 #preds=4 #tokens=11598 acibench_D2N140_virtscribe_clinicalnlp_taskC_test2\n",
    "DescF1:0.553 (0.717/0.450)  ReasF1:0.021 (0.500/0.011)  OTypF1:0.667 (1.000/0.500)  ProvF1:0.336 (0.800/0.212)\n",
    "idx=4: 3.3289s #targets=2 #preds=4 #tokens=10299 acibench_D2N067_aci_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1263c-360f-46cb-8710-3509e2299f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from llama_cpp import Llama, LlamaGrammar\n",
    "from llama_cpp.llama_speculative import LlamaPromptLookupDecoding\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%cd mediqa-oe/evaluation\n",
    "from evaluate_oe import evaluate_sample\n",
    "evaluate_sample\n",
    "%cd ../..\n",
    "\n",
    "with open('data/orders_data_transcript.json', 'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "allids = [_['id'] for _ in data['dev']]\n",
    "\n",
    "dev_extract = data['dev'][:12]\n",
    "\n",
    "dev_extract_orders = {\n",
    "    d['id']: d['expected_orders'] for d in dev_extract\n",
    "}\n",
    "with open('data/dev_extract_orders.json', 'w') as f:\n",
    "    json.dump(dev_extract_orders, f)\n",
    "\n",
    "startmodelloading_time = time.time()\n",
    "\n",
    "mname = \"/home/justin/llama/Qwen3-8B-UD-Q5_K_XL.gguf\"\n",
    "mname = \"/home/justin/llama/Qwen3-14B-UD-Q4_K_XL.gguf\"\n",
    "try:\n",
    "    llm\n",
    "except NameError:\n",
    "    print('Loading model')\n",
    "    llm = Llama(\n",
    "        # model_path=\"/home/justin/llama/Qwen3-8B-Q5_K_M.gguf\",  \n",
    "        # lora_path='llama_8b_unsloth_mediqa_oe_adapter_model.safetensors',\n",
    "        model_path=mname,  \n",
    "        # lora_path='unsloth.Q4_K_M.gguf',\n",
    "        # model_path=\"/home/justin/llama/Qwen3-14B-Q4_K_M.gguf\",  \n",
    "        # model_path=\"/home/justin/llama/Qwen3-14B-UD-Q4_K_XL.gguf\",  \n",
    "        # model_path=\"/home/justin/llama/Qwen3-4B-Q6_K.gguf\",  \n",
    "        draft_model=LlamaPromptLookupDecoding(),\n",
    "        logits_all=True,\n",
    "        n_gpu_layers=-1,\n",
    "        flash_attn=True,\n",
    "        # n_ctx=int(4096*5.7),\n",
    "        # n_ctx=int(4096*7),\n",
    "        n_ctx=int(4096*7),\n",
    "        verbose=False,\n",
    "        n_threads=os.cpu_count() - 2\n",
    "    )\n",
    "    print(f'Loaded model {time.time()-startmodelloading_time:.4f}s.')\n",
    "\n",
    "def shorten_transcript(s):\n",
    "    s = str(s)\n",
    "    s = s.replace('turn_id', 'turn').replace('DOCTOR', 'DOC').replace('PATIENT', 'PAT').replace('transcript', 'txt')\n",
    "    return s\n",
    "\n",
    "\n",
    "train_examples_predicted_turns = {\n",
    "    'acibench_D2N074_virtscribe_valid': [10, 14],\n",
    "    'primock57_2_6': [184, 185, 186, 189, 190, 180, 181, 183, 191, 192],\n",
    "    'acibench_D2N025_virtscribe_train': [80, 88, 90, 96, 133],\n",
    "    'primock57_1_2': [80, 88, 90, 96, 133],    \n",
    "}\n",
    "\n",
    "def get_salient_transcript(sample):\n",
    "    expected_output = sample['expected_orders']\n",
    "    transcript = sample['transcript']\n",
    "    salient_turns = [__ for _ in expected_output for __ in _['provenance']]\n",
    "    salient_turns += train_examples_predicted_turns[sample['id']]\n",
    "    salient_turns += [_-3 for _ in salient_turns]\n",
    "    salient_turns += [_-2 for _ in salient_turns]\n",
    "    salient_turns += [_-1 for _ in salient_turns]\n",
    "    salient_turns += [_+1 for _ in salient_turns]\n",
    "    salient_turns += [_+2 for _ in salient_turns]\n",
    "    salient_turns += [_+3 for _ in salient_turns]\n",
    "    salient_turns = sorted(set(salient_turns))\n",
    "    salient_transcript = [transcript[idx] for idx in salient_turns if idx<len(transcript)]\n",
    "    return salient_transcript\n",
    "\n",
    "examplestr = \\\n",
    "f\"\"\"\n",
    "EXAMPLE1START\n",
    "Transcript:\n",
    "{shorten_transcript(data['train'][0]['transcript'])}\n",
    "Desired output:\n",
    "{data['train'][0]['expected_orders']}\n",
    "EXAMPLE1END\n",
    "\n",
    "EXAMPLE2START\n",
    "Transcript:\n",
    "{shorten_transcript(data['train'][-1]['transcript'])}\n",
    "Desired output:\n",
    "{data['train'][-1]['expected_orders']}\n",
    "EXAMPLE2END\n",
    "\"\"\".replace('\\'', '\"')\n",
    "\n",
    "def get_train_sample_from_idname(idname):\n",
    "    return [_ for _ in data['train'] if idname in _['id']][0]\n",
    "\n",
    "example_transcripts = [get_salient_transcript(get_train_sample_from_idname(idname)) for idname in train_examples_predicted_turns]\n",
    "example_transcripts = [shorten_transcript(_) for _ in example_transcripts]\n",
    "example_outputs = [get_train_sample_from_idname(idname)['expected_orders'] for idname in train_examples_predicted_turns]\n",
    "\n",
    "examplestr = \"\".join([f\"EXAMPLE{idx+1}START\\nTranscript:\\n{transcript}\\nExpected output:\\n{output}\\n\" for idx, (transcript, output) in enumerate(zip(example_transcripts, example_outputs))]).replace('\\'', '\"')\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are an assistant for extracting medical orders from transcripts of patient doctor conversations.\n",
    "\n",
    "Medical order extraction involves identifying and structuring various medical orders —such as medications, imaging studies, lab tests, and follow-ups— based on doctor-patient conversations. \n",
    "\n",
    "The conversation is given to you in the format of a list of dicts with turn, speaker (doctor or patient), and txt for each turn.\n",
    "\n",
    "You are to return a list of dicts with these keys: order_type, description, reason, and provenance. \n",
    "\n",
    "1. Return a list with one dict for each order from the conversation. Your output will be parsed with json.loads().\n",
    "2. If there is only a single order, still return a list.\n",
    "3. There are only four allowed values for the order_type: \"medication\", \"lab\", \"followup\", \"imaging\"\n",
    "4. Provenance should be a list of ints relating to the turn ids that ground the order. This is the turn where the order was made, and maybe include directly preceeding turns where the reason was mentioned.\n",
    "5. Quote the reason verbatim from the text.\n",
    "6. Only list *new* or repeat orders. Do not list things that the patient is to continue doing that are mentioned in passing. Do not list previous exams.\n",
    "7. The above point (6.) is very important. Orders that have a \"continue\" status (e.g. \"we will continue with xanax XXmg\") are NOT considered valid orders, since we dont need to place a specific order in EHR for instance.\n",
    "8. Lab orders are fine-grained, i.e. each test is one order.\n",
    "9. If the doctor suggests an over the counter medication (e.g. pain killers), we also count that as an order - UNLESS the patient is already taking it (remember rule 6!)\n",
    "10. Only count orders that are actually made, not ones that are conditional (if your pain persists, maybe we...).\n",
    "\n",
    "Make sure your output is a list (i.e. starts and ends with square brackets) of dicts, separated by commas.\n",
    "\n",
    "Examples:\n",
    "{examplestr}\n",
    "\"\"\"\n",
    "\n",
    "#You are scored using these metrics: description_Rouge1_f1, reason_Rouge1_f1, order_type_Strict_f1 and provenance_MultiLabel_f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7666954-b495-4d59-9188-8ea00c45322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use = [_ for _ in data['dev'] if _['id'] not in train_examples_predicted_turns]#data['train'][:]\n",
    "all_preds = {}\n",
    "all_metrics = {}\n",
    "metrics_per_sample = {}\n",
    "for idx, curr_sample in enumerate(tqdm(data_to_use)):\n",
    "    curr_sample = data_to_use[idx]\n",
    "    curr_transcript = shorten_transcript(curr_sample['transcript'])\n",
    "    \n",
    "    user_prompt = f\"Please process this transcript.\\nTRANSCRIPTSTART\\n{curr_transcript}\\nTRANSCRIPTEND\\nPlease follow all the rules and instructions carefully. Reply only with the valid response in the desired format.\"\n",
    "    prompt=f\"\"\"\n",
    "    <|im_start|>system{system_prompt}<|im_end|>\n",
    "    <|im_start|>user\\n{user_prompt} \\\\nothink<|im_end|>\n",
    "    <|im_start|>assistant\\n<think>\\n</think>\\n[\"\"\"\n",
    "    start = time.time()\n",
    "    response = llm.create_completion(\n",
    "        prompt=prompt,\n",
    "        max_tokens=int(4096*0.5),\n",
    "        temperature=0., top_k=1, top_p=1.0,\n",
    "        stop=[]\n",
    "    )\n",
    "    curr_time = time.time()-start\n",
    "    \n",
    "    pred = '['+response['choices'][0]['text']\n",
    "    if \"</think>\" in pred:\n",
    "        thought_trace = pred.split('</think>')[0]\n",
    "        print(thought_trace)\n",
    "        pred = pred.split('</think>')[-1]\n",
    "    try:\n",
    "        try:\n",
    "            pred = json.loads(pred)\n",
    "        except:\n",
    "            pred = json.loads('['+pred+']')\n",
    "            print(f'{idx=} was fixed with adding square brackets')\n",
    "        if isinstance(pred, dict):\n",
    "            print(f'{idx=} was a dict, we made it a list')\n",
    "            pred = [pred]\n",
    "    except:\n",
    "        print(f'{idx} is not proper json.\\n{pred}')\n",
    "        pred = []\n",
    "\n",
    "    all_preds[curr_sample['id']] = pred\n",
    "\n",
    "    t = {curr_sample['id']: curr_sample['expected_orders']}\n",
    "    p = {curr_sample['id']: pred}\n",
    "    metrics = evaluate_sample(t, p)\n",
    "    metricstr = f\"DescF1:{metrics['description']['Rouge1_f1']:.3f} ({metrics['description']['Rouge1_recall']:.3f}/{metrics['description']['Rouge1_precision']:.3f})\"\n",
    "    metricstr += f\"  ReasF1:{metrics['reason']['Rouge1_f1']:.3f} ({metrics['reason']['Rouge1_recall']:.3f}/{metrics['reason']['Rouge1_precision']:.3f})\"\n",
    "    metricstr += f\"  OTypF1:{metrics['order_type']['Strict_f1']:.3f} ({metrics['order_type']['Strict_recall']:.3f}/{metrics['order_type']['Strict_precision']:.3f})\"\n",
    "    metricstr += f\"  ProvF1:{metrics['provenance']['MultiLabel_f1']:.3f} ({metrics['provenance']['MultiLabel_recall']:.3f}/{metrics['provenance']['MultiLabel_precision']:.3f})\"\n",
    "\n",
    "    num_tokens = response['usage']['total_tokens']\n",
    "    num_targets = len(curr_sample['expected_orders'])\n",
    "    num_preds = len(pred)\n",
    "    print(f'{idx=}: {curr_time:.4f}s #targets={num_targets} #preds={num_preds} #tokens={num_tokens} {curr_sample[\"id\"]}')\n",
    "    \n",
    "    print(metricstr)\n",
    "    all_metrics[curr_sample['id']] = metrics\n",
    "    metrics_per_sample[curr_sample['id']] = [metrics['description']['Rouge1_f1'], \n",
    "                                             metrics['reason']['Rouge1_f1'],\n",
    "                                             metrics['order_type']['Strict_f1'],\n",
    "                                             metrics['provenance']['MultiLabel_f1'],\n",
    "                                            \n",
    "                                             curr_time,\n",
    "                                             num_preds,\n",
    "                                             num_targets,\n",
    "                                             num_tokens,\n",
    "                                            ]\n",
    "    # print()\n",
    "\n",
    "print('Done')\n",
    "mname_short = mname.split('/')[-1].split('.gguf')[0].replace('Qwen','qw')\n",
    "savestr = f'dev_ALL_{mname_short}_shortenedexs'\n",
    "# # 'dev_ALL_qw14BUDQ4KXL_v5dot6_ex_specdec'\n",
    "# with open('data/dev_ALL_qw8BQ5KM_v5dot7noex.json', 'w') as f:\n",
    "#     json.dump(all_preds, f)\n",
    "with open(f'data/{savestr}.json', 'w') as f:\n",
    "    json.dump(all_preds, f)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(metrics_per_sample).T\n",
    "df.columns = ['descF1', 'reasonF1', 'ordertypeF1', 'provF1', 'processingtime', 'len_pred', 'len_target', 'total_tokens']\n",
    "df['avg'] = df[['descF1', 'reasonF1', 'ordertypeF1', 'provF1']].mean(axis=1)\n",
    "print(df.mean(axis=0).round(3))\n",
    "df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48720c7c-f6cd-4393-8cec-e5aff76236b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b37c46-5589-48b2-91ce-aca92c8f6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "savestr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
